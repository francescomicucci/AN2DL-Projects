{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["QsbajqEUgt9t","eEgwKE3Mg1Tq","0s7diZvh4nAO","I8i5wL4C_PGH","C3fSMz4z1Ihk"],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"QsbajqEUgt9t"},"source":["### Connect to Drive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GSpVDgFDgh7s"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive/My Drive/Progetto AN2DL"]},{"cell_type":"markdown","source":["### Import libraries"],"metadata":{"id":"eEgwKE3Mg1Tq"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"aR-w0eZ-ABIT","executionInfo":{"status":"ok","timestamp":1703270696234,"user_tz":-60,"elapsed":16,"user":{"displayName":"Francesco Micucci","userId":"15292666692711947430"}}},"outputs":[],"source":["# Fix randomness and hide warnings\n","seed = 5\n","\n","import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","os.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'\n","\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","warnings.simplefilter(action='ignore', category=Warning)\n","\n","import numpy as np\n","np.random.seed(seed)\n","\n","import logging\n","\n","import random\n","random.seed(seed)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7775,"status":"ok","timestamp":1703270704000,"user":{"displayName":"Francesco Micucci","userId":"15292666692711947430"},"user_tz":-60},"id":"e06wPZJbADcv","outputId":"d4020613-5d73-48b2-fb7d-3f09f53f8ed6"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.15.0\n"]}],"source":["# Import tensorflow\n","import tensorflow as tf\n","from tensorflow import keras as tfk\n","from tensorflow.keras import layers as tfkl\n","tf.autograph.set_verbosity(0)\n","tf.get_logger().setLevel(logging.ERROR)\n","tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n","tf.random.set_seed(seed)\n","tf.compat.v1.set_random_seed(seed)\n","print(tf.__version__)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"fN6wKImkADfL","executionInfo":{"status":"ok","timestamp":1703270704424,"user_tz":-60,"elapsed":434,"user":{"displayName":"Francesco Micucci","userId":"15292666692711947430"}}},"outputs":[],"source":["# Import other libraries\n","import pandas as pd\n","import seaborn as sns\n","from datetime import datetime\n","import matplotlib.pyplot as plt\n","plt.rc('font', size=16)\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import RobustScaler"]},{"cell_type":"markdown","source":["### Functions"],"metadata":{"id":"0s7diZvh4nAO"}},{"cell_type":"code","source":["def inspect_data(data, periods, categories, rows):\n","  figs, axs = plt.subplots(len(rows), 1, figsize=(17,17))\n","  for i, row in enumerate(rows):\n","        axs[i].plot(data[row])\n","        axs[i].set_title(\"Number \" +str(row)+ \", Category \" +str(categories[row]))\n","        axs[i].set_xlim(periods[row])\n","  plt.show()"],"metadata":{"id":"8chCNpni4n_l","executionInfo":{"status":"ok","timestamp":1703270704754,"user_tz":-60,"elapsed":344,"user":{"displayName":"Francesco Micucci","userId":"15292666692711947430"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def build_sequences(data, lenghts, window=200, stride=20, telescope=9):\n","  assert window % stride == 0\n","\n","  dataset = []\n","  labels = []\n","  for i in np.arange(data.shape[0]):\n","    check = lenghts[i][0] % window - telescope\n","    size = (window - check) % window\n","    if size > 0 and data.shape[1] - lenghts[i][0] - size < 0:\n","      padding = np.zeros(size - (data.shape[1] - lenghts[i][0]), dtype='float32')\n","      temp_data = np.concatenate((padding, data[i]))\n","    else:\n","      temp_data = data[i].copy()\n","\n","    for idx in np.arange(temp_data.shape[0]-lenghts[i][0]-size, temp_data.shape[0]-window-telescope, stride):\n","      dataset.append(temp_data[idx:idx+window])\n","      labels.append(temp_data[idx+window:idx+window+telescope])\n","\n","  dataset = np.array(dataset)\n","  labels = np.array(labels)\n","\n","  return dataset, labels"],"metadata":{"id":"1jDPT_1EQxyZ","executionInfo":{"status":"ok","timestamp":1703270704755,"user_tz":-60,"elapsed":17,"user":{"displayName":"Francesco Micucci","userId":"15292666692711947430"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["### Training settings"],"metadata":{"id":"I8i5wL4C_PGH"}},{"cell_type":"code","source":["# Set variables used for training\n","epochs        = 200\n","batch_size    = 32\n","window        = 200\n","stride        = 200\n","telescope     = 9\n","\n","early_stopping = tfk.callbacks.EarlyStopping(\n","                  monitor='val_loss',\n","                  mode='min',\n","                  patience=10,\n","                  restore_best_weights=True)\n","\n","lr_scheduling = tfk.callbacks.ReduceLROnPlateau(\n","                  monitor='val_loss',\n","                  mode='min',\n","                  patience=5,\n","                  factor=0.99,\n","                  min_lr=1e-5)\n","\n","callbacks = [early_stopping, lr_scheduling]"],"metadata":{"id":"fzZZI3VX-esj","executionInfo":{"status":"ok","timestamp":1703270704756,"user_tz":-60,"elapsed":16,"user":{"displayName":"Francesco Micucci","userId":"15292666692711947430"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def build_CONV_LSTM_model(input_shape, output_shape):\n","    # Ensure the input time steps are at least as many as the output time steps\n","    assert input_shape[0] >= output_shape[0], \"For this exercise we want input time steps to be >= of output time steps\"\n","\n","    # Define the input layer with the specified shape\n","    input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n","\n","    # Add a Bidirectional LSTM layer with 64 units\n","    x = tfkl.Bidirectional(tfkl.LSTM(64, return_sequences=True, name='lstm'), name='bidirectional_lstm')(input_layer)\n","\n","    # Add a 1D Convolution layer with 128 filters and a kernel size of 1\n","    x = tfkl.Conv1D(128, 1, padding='same', activation='relu', name='conv')(x)\n","\n","    # Add a final Convolution layer to match the desired output shape\n","    output_layer = tfkl.Conv1D(output_shape[1], 1, padding='same', name='output_layer')(x)\n","\n","    # Calculate the size to crop from the output to match the output shape\n","    crop_size = output_layer.shape[1] - output_shape[0]\n","\n","    # Crop the output to the desired length\n","    output_layer = tfkl.Cropping1D((0, crop_size), name='cropping')(output_layer)\n","\n","    output_layer = output_layer[:,:,0]\n","\n","    # Construct the model by connecting input and output layers\n","    model = tf.keras.Model(inputs=input_layer, outputs=output_layer, name='CONV_LSTM_model')\n","\n","    # Compile the model with Mean Squared Error loss and Adam optimizer\n","    model.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=tf.keras.optimizers.Adam())\n","\n","    return model"],"metadata":{"id":"bT6jBsQDAFqx","executionInfo":{"status":"ok","timestamp":1703270704756,"user_tz":-60,"elapsed":14,"user":{"displayName":"Francesco Micucci","userId":"15292666692711947430"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["### Training"],"metadata":{"id":"C3fSMz4z1Ihk"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Z6wgw2kXEAQ"},"outputs":[],"source":["# Load data\n","data_train = np.load('training_dataset/split_dataset/data_train.npy', allow_pickle=True)\n","periods_train = np.load('training_dataset/split_dataset/periods_train.npy', allow_pickle=True)\n","categories_train = np.load('training_dataset/split_dataset/category_train.npy', allow_pickle=True)\n","data_val = np.load('training_dataset/split_dataset/data_val.npy', allow_pickle=True)\n","periods_val = np.load('training_dataset/split_dataset/periods_val.npy', allow_pickle=True)\n","categories_val = np.load('training_dataset/split_dataset/category_val.npy', allow_pickle=True)\n","\n","inspect_data(data_train, periods_train, categories_train, [100, 40000, 14000])"]},{"cell_type":"code","source":["X_train, y_train = build_sequences(\n","    data = data_train,\n","    lenghts = np.diff(periods_train),\n","    window = window,\n","    stride = stride,\n","    telescope = telescope\n",")\n","\n","X_val, y_val = build_sequences(\n","    data = data_val,\n","    lenghts = np.diff(periods_val),\n","    window = window,\n","    stride = stride,\n","    telescope = telescope\n",")\n","\n","input_shape   = (X_train.shape[1],1)\n","output_shape  = (y_train.shape[1],1)\n","\n","print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n","print(f\"X_val: {X_val.shape}, y_train: {y_val.shape}\")\n","print(f\"Input shape: {input_shape}, output shape: {output_shape}\")"],"metadata":{"id":"tRC5TR8W9NVc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define model\n","model = build_CONV_LSTM_model(input_shape, output_shape)\n","model.summary()\n","tfk.utils.plot_model(model, expand_nested=True, show_shapes=True)"],"metadata":{"id":"excSV1JlASjX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train the model\n","history = model.fit(\n","    x = X_train,\n","    y = y_train,\n","    batch_size = batch_size,\n","    epochs = epochs,\n","    validation_data=(X_val, y_val),\n","    callbacks = callbacks\n",").history"],"metadata":{"id":"WUjUxOz0AV0T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save model\n","model.save('StartingModel')"],"metadata":{"id":"ACcGTtIIAlwh","executionInfo":{"status":"ok","timestamp":1703271111881,"user_tz":-60,"elapsed":42512,"user":{"displayName":"Francesco Micucci","userId":"15292666692711947430"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Plot important informations\n","best_epoch = np.argmin(history['val_loss'])\n","plt.figure(figsize=(17,4))\n","plt.plot(history['loss'], label='Training loss', alpha=.8, color='#ff7f0e')\n","plt.plot(history['val_loss'], label='Validation loss', alpha=.9, color='#5a9aa5')\n","plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n","plt.title('Mean Squared Error')\n","plt.legend()\n","plt.grid(alpha=.3)\n","plt.show()\n","\n","plt.figure(figsize=(18,3))\n","plt.plot(history['lr'], label='Learning Rate', alpha=.8, color='#ff7f0e')\n","plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n","plt.legend()\n","plt.grid(alpha=.3)\n","plt.show()"],"metadata":{"id":"3W3Gfs9UAwx0"},"execution_count":null,"outputs":[]}]}