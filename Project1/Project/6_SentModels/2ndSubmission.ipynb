{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"16JjKTJRbWh-"},"source":["### Connect to Drive"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"tqL-AIAkX2vy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700306754240,"user_tz":-60,"elapsed":16848,"user":{"displayName":"Francesco Micucci","userId":"18194798004491641315"}},"outputId":"dfbb832f-d6d5-41fc-fc79-e23bab9e2d89"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n","/gdrive/My Drive/Progetto AN2DL/6_SentModels\n"]}],"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive/My Drive/Progetto AN2DL/6_SentModels"]},{"cell_type":"markdown","metadata":{"id":"_eqDRT-ecAlb"},"source":["### Import libraries"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"5mLdC-wZcBaz","executionInfo":{"status":"ok","timestamp":1700306754241,"user_tz":-60,"elapsed":8,"user":{"displayName":"Francesco Micucci","userId":"18194798004491641315"}}},"outputs":[],"source":["# Hide warnings\n","import os\n","\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","warnings.simplefilter(action='ignore', category=Warning)\n","\n","import numpy as np\n","\n","import logging"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6720,"status":"ok","timestamp":1700306760955,"user":{"displayName":"Francesco Micucci","userId":"18194798004491641315"},"user_tz":-60},"id":"XdPCmvhfcNSQ","outputId":"92e03faf-a482-470b-a143-333be8bd3dbb"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.14.0\n"]}],"source":["# Import tensorflow\n","import tensorflow as tf\n","from tensorflow import keras as tfk\n","from tensorflow.keras import layers as tfkl\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","tf.autograph.set_verbosity(0)\n","tf.get_logger().setLevel(logging.ERROR)\n","tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n","print(tf.__version__)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"oBrQWONLcPOn","executionInfo":{"status":"ok","timestamp":1700306762181,"user_tz":-60,"elapsed":1235,"user":{"displayName":"Francesco Micucci","userId":"18194798004491641315"}}},"outputs":[],"source":["# Import other libraries\n","import cv2\n","from tensorflow.keras.applications.mobilenet import preprocess_input\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split, KFold\n","import pickle\n","from tqdm import tqdm"]},{"cell_type":"markdown","metadata":{"id":"O0A6y0bKc96a"},"source":["### Load and process the dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4608,"status":"ok","timestamp":1700306766773,"user":{"displayName":"Francesco Micucci","userId":"18194798004491641315"},"user_tz":-60},"id":"z_ivPgQolP2i","outputId":"54b4a6f8-9bbd-44e6-d4ed-0858c0dcf789"},"outputs":[{"output_type":"stream","name":"stdout","text":["(5004, 96, 96, 3) (5004,)\n"]}],"source":["# Load data\n","data = np.load('../clean_data.npz', allow_pickle=True)\n","\n","# Save labels in a new list (image pixel values are float in [0, 1])\n","images = data['data']\n","\n","# Save labels in a new list\n","labels = data['labels']\n","\n","# Print data shape\n","print(images.shape, labels.shape)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1700306766774,"user":{"displayName":"Francesco Micucci","userId":"18194798004491641315"},"user_tz":-60},"id":"Us_gXVtGuveA"},"outputs":[],"source":["# Convert labels from string to integer\n","num_labels = []\n","for label in labels:\n","  if label == \"healthy\":\n","    num_labels.append(0)\n","  else:\n","    num_labels.append(1)\n","\n","# Convert labels in the one-hot encoding format\n","num_labels = np.array(num_labels)\n","labels = tfk.utils.to_categorical(num_labels, 2)"]},{"cell_type":"markdown","metadata":{"id":"QL0QUFcPM8Sl"},"source":["### ConvNeXtLarge"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":20277,"status":"ok","timestamp":1700306787045,"user":{"displayName":"Francesco Micucci","userId":"18194798004491641315"},"user_tz":-60},"id":"aVZRGBAVM_Sh","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2f82407b-848c-494a-d238-888a9a0cbec4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/convnext/convnext_large_notop.h5\n","785596384/785596384 [==============================] - 9s 0us/step\n"]}],"source":["# Import Feature Extractor with specified settings\n","feature_extractor = tfk.applications.ConvNeXtLarge(\n","    input_shape=(96, 96, 3),\n","    include_top=False,\n","    weights=\"imagenet\",\n","    pooling='avg',\n","    include_preprocessing=True,\n",")"]},{"cell_type":"markdown","metadata":{"id":"hEXQXOpvM_7m"},"source":["### Initial setup"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"5ZOP5_o3NAJM","executionInfo":{"status":"ok","timestamp":1700306787047,"user_tz":-60,"elapsed":27,"user":{"displayName":"Francesco Micucci","userId":"18194798004491641315"}}},"outputs":[],"source":["# Define network parameters/callbacks\n","dropout_rate = 1/10\n","learning_rate = 1e-3\n","\n","lr_scheduler = tfk.callbacks.ReduceLROnPlateau(\n","    monitor='val_accuracy',\n","    patience=5,\n","    factor=0.99,\n","    mode='max',\n","    min_lr=1e-5\n",")\n","\n","early_stopping = tfk.callbacks.EarlyStopping(\n","    monitor='val_accuracy',\n","    mode='max',\n","    patience=15,\n","    restore_best_weights=True\n",")"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"Gay8HrAKNgXA","executionInfo":{"status":"ok","timestamp":1700306787047,"user_tz":-60,"elapsed":23,"user":{"displayName":"Francesco Micucci","userId":"18194798004491641315"}}},"outputs":[],"source":["def build_model(feature_extractor, dropout_rate, learning_rate=0.001):\n","  # Use the supernet as feature extractor, i.e. freeze all its weigths\n","  feature_extractor.trainable = False\n","\n","  # Create an input layer with shape (96, 96, 3)\n","  inputs = tfk.Input(shape=(96, 96, 3), name='Input')\n","\n","  # Connect FeatureExtractor to the input\n","  x = feature_extractor(inputs)\n","\n","  # Hidden layers\n","  x = tfkl.Dense(units=256, name='HiddenDense1')(x)\n","  x = tfkl.Activation('relu', name='HiddenActivation1')(x)\n","  dropout = tfkl.Dropout(dropout_rate)(x)\n","  x = tfkl.Dense(units=256, name='HiddenDense2')(dropout)\n","  x = tfkl.Activation('relu', name='HiddenActivation2')(x)\n","  dropout = tfkl.Dropout(dropout_rate)(x)\n","\n","  # Add a Dense layer with 2 unit and softmax activation as the classifier\n","  outputs = tfkl.Dense(2, activation='softmax')(dropout)\n","\n","  # Create a Model connecting input and output\n","  model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n","\n","  # Compile the model with Categorical Cross-Entropy loss and Adam optimizer\n","  model.compile(loss=tfk.losses.CategoricalCrossentropy(),\n","                optimizer=tfk.optimizers.Adam(learning_rate),\n","                metrics=['accuracy'])\n","\n","  # Return the model\n","  return model"]},{"cell_type":"markdown","source":["### K-Fold + Transfer Learning"],"metadata":{"id":"JupOgn7-mNBA"}},{"cell_type":"code","source":["# Define the number of folds for cross-validation\n","num_folds = 10\n","\n","# Initialize lists to store training histories, scores, and best epochs\n","histories = []\n","scores = []\n","best_epochs = []\n","\n","# Create a KFold cross-validation object\n","kfold = KFold(n_splits=num_folds, shuffle=True)\n","\n","# Loop through each fold\n","for fold_idx, (train_idx, valid_idx) in enumerate(kfold.split(images, labels)):\n","\n","  print(\"Starting training on fold num: {}\".format(fold_idx+1))\n","\n","  # Init model\n","  k_model = build_model(feature_extractor, dropout_rate, learning_rate)\n","  train_datagen = ImageDataGenerator(\n","          horizontal_flip = True,\n","          vertical_flip = True,\n","          width_shift_range = 0.1,\n","          height_shift_range = 0.1,\n","          rotation_range=10.,\n","          fill_mode='reflect')\n","\n","  train_datagen.fit((images)[train_idx]*255)\n","\n","  # Train the model on the training data for this fold\n","  history = k_model.fit_generator(\n","      train_datagen.flow((images)[train_idx]*255, labels[train_idx], batch_size=16),\n","      epochs=200,\n","      steps_per_epoch=len((images)[train_idx])/16,\n","      validation_data = ((images)[valid_idx]*255, labels[valid_idx]),\n","      callbacks = [early_stopping, lr_scheduler]\n","      ).history\n","\n","  # Evaluate the model on the validation data for this fold\n","  score = k_model.evaluate((images)[valid_idx]*255, labels[valid_idx], verbose=0)\n","  scores.append(score[1])\n","\n","  # Calculate the best epoch for early stopping\n","  best_epoch = len(history['loss']) - 15\n","  best_epochs.append(best_epoch)\n","\n","  # Store the training history for this fold\n","  histories.append(history)"],"metadata":{"id":"r_L-lvvemSxD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8bdf52d4-1048-4610-d415-22ef01079047","executionInfo":{"status":"ok","timestamp":1700306385026,"user_tz":-60,"elapsed":12849161,"user":{"displayName":"Francesco Micucci","userId":"18194798004491641315"}}},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting training on fold num: 1\n","Epoch 1/200\n","281/281 [==============================] - 80s 174ms/step - loss: 0.5180 - accuracy: 0.7517 - val_loss: 0.3755 - val_accuracy: 0.8443 - lr: 0.0010\n","Epoch 2/200\n","281/281 [==============================] - 30s 107ms/step - loss: 0.3892 - accuracy: 0.8306 - val_loss: 0.3844 - val_accuracy: 0.8343 - lr: 0.0010\n","Epoch 3/200\n","281/281 [==============================] - 29s 103ms/step - loss: 0.3322 - accuracy: 0.8539 - val_loss: 0.3387 - val_accuracy: 0.8443 - lr: 0.0010\n","Epoch 4/200\n","281/281 [==============================] - 31s 108ms/step - loss: 0.3148 - accuracy: 0.8621 - val_loss: 0.3410 - val_accuracy: 0.8563 - lr: 0.0010\n","Epoch 5/200\n","281/281 [==============================] - 31s 112ms/step - loss: 0.2910 - accuracy: 0.8761 - val_loss: 0.3012 - val_accuracy: 0.8583 - lr: 0.0010\n","Epoch 6/200\n","281/281 [==============================] - 30s 105ms/step - loss: 0.2832 - accuracy: 0.8803 - val_loss: 0.2882 - val_accuracy: 0.8743 - lr: 0.0010\n","Epoch 7/200\n","281/281 [==============================] - 32s 113ms/step - loss: 0.2724 - accuracy: 0.8830 - val_loss: 0.2988 - val_accuracy: 0.8862 - lr: 0.0010\n","Epoch 8/200\n","281/281 [==============================] - 31s 111ms/step - loss: 0.2652 - accuracy: 0.8881 - val_loss: 0.2893 - val_accuracy: 0.8723 - lr: 0.0010\n","Epoch 9/200\n","281/281 [==============================] - 28s 100ms/step - loss: 0.2553 - accuracy: 0.8890 - val_loss: 0.3077 - val_accuracy: 0.8643 - lr: 0.0010\n","Epoch 10/200\n","281/281 [==============================] - 31s 109ms/step - loss: 0.2454 - accuracy: 0.9016 - val_loss: 0.2580 - val_accuracy: 0.8882 - lr: 0.0010\n","Epoch 11/200\n","281/281 [==============================] - 34s 122ms/step - loss: 0.2395 - accuracy: 0.8956 - val_loss: 0.2466 - val_accuracy: 0.9082 - lr: 0.0010\n","Epoch 12/200\n","281/281 [==============================] - 33s 115ms/step - loss: 0.2303 - accuracy: 0.9021 - val_loss: 0.2568 - val_accuracy: 0.8902 - lr: 0.0010\n","Epoch 13/200\n","281/281 [==============================] - 33s 115ms/step - loss: 0.2167 - accuracy: 0.9089 - val_loss: 0.2807 - val_accuracy: 0.8862 - lr: 0.0010\n","Epoch 14/200\n","281/281 [==============================] - 32s 112ms/step - loss: 0.2176 - accuracy: 0.9127 - val_loss: 0.2495 - val_accuracy: 0.8743 - lr: 0.0010\n","Epoch 15/200\n","281/281 [==============================] - 31s 109ms/step - loss: 0.2059 - accuracy: 0.9132 - val_loss: 0.2463 - val_accuracy: 0.8902 - lr: 0.0010\n","Epoch 16/200\n","281/281 [==============================] - 30s 106ms/step - loss: 0.2094 - accuracy: 0.9141 - val_loss: 0.3795 - val_accuracy: 0.8363 - lr: 0.0010\n","Epoch 17/200\n","281/281 [==============================] - 33s 117ms/step - loss: 0.2040 - accuracy: 0.9163 - val_loss: 0.2522 - val_accuracy: 0.8902 - lr: 9.9000e-04\n","Epoch 18/200\n","281/281 [==============================] - 32s 115ms/step - loss: 0.1922 - accuracy: 0.9194 - val_loss: 0.2615 - val_accuracy: 0.8842 - lr: 9.9000e-04\n","Epoch 19/200\n","281/281 [==============================] - 32s 114ms/step - loss: 0.2004 - accuracy: 0.9194 - val_loss: 0.2323 - val_accuracy: 0.9022 - lr: 9.9000e-04\n","Epoch 20/200\n","281/281 [==============================] - 30s 108ms/step - loss: 0.1869 - accuracy: 0.9285 - val_loss: 0.2737 - val_accuracy: 0.8802 - lr: 9.9000e-04\n","Epoch 21/200\n","281/281 [==============================] - 31s 111ms/step - loss: 0.1943 - accuracy: 0.9174 - val_loss: 0.2747 - val_accuracy: 0.8822 - lr: 9.9000e-04\n","Epoch 22/200\n","281/281 [==============================] - 32s 113ms/step - loss: 0.1762 - accuracy: 0.9294 - val_loss: 0.2314 - val_accuracy: 0.9102 - lr: 9.8010e-04\n","Epoch 23/200\n","281/281 [==============================] - 29s 104ms/step - loss: 0.1714 - accuracy: 0.9272 - val_loss: 0.2432 - val_accuracy: 0.8922 - lr: 9.8010e-04\n","Epoch 24/200\n","281/281 [==============================] - 32s 112ms/step - loss: 0.1720 - accuracy: 0.9265 - val_loss: 0.2174 - val_accuracy: 0.9122 - lr: 9.8010e-04\n","Epoch 25/200\n","281/281 [==============================] - 31s 110ms/step - loss: 0.1727 - accuracy: 0.9320 - val_loss: 0.2133 - val_accuracy: 0.9242 - lr: 9.8010e-04\n","Epoch 26/200\n","281/281 [==============================] - 28s 100ms/step - loss: 0.1622 - accuracy: 0.9329 - val_loss: 0.2309 - val_accuracy: 0.9082 - lr: 9.8010e-04\n","Epoch 27/200\n","281/281 [==============================] - 32s 114ms/step - loss: 0.1737 - accuracy: 0.9314 - val_loss: 0.2434 - val_accuracy: 0.8822 - lr: 9.8010e-04\n","Epoch 28/200\n","281/281 [==============================] - 29s 104ms/step - loss: 0.1680 - accuracy: 0.9307 - val_loss: 0.2219 - val_accuracy: 0.9082 - lr: 9.8010e-04\n","Epoch 29/200\n","281/281 [==============================] - 31s 111ms/step - loss: 0.1501 - accuracy: 0.9403 - val_loss: 0.2993 - val_accuracy: 0.8962 - lr: 9.8010e-04\n","Epoch 30/200\n","281/281 [==============================] - 30s 107ms/step - loss: 0.1625 - accuracy: 0.9332 - val_loss: 0.2795 - val_accuracy: 0.8922 - lr: 9.8010e-04\n","Epoch 31/200\n","281/281 [==============================] - 28s 101ms/step - loss: 0.1547 - accuracy: 0.9405 - val_loss: 0.2256 - val_accuracy: 0.9142 - lr: 9.7030e-04\n","Epoch 32/200\n","281/281 [==============================] - 32s 113ms/step - loss: 0.1479 - accuracy: 0.9405 - val_loss: 0.2400 - val_accuracy: 0.9062 - lr: 9.7030e-04\n","Epoch 33/200\n","281/281 [==============================] - 33s 118ms/step - loss: 0.1479 - accuracy: 0.9405 - val_loss: 0.2556 - val_accuracy: 0.9122 - lr: 9.7030e-04\n","Epoch 34/200\n","281/281 [==============================] - 32s 113ms/step - loss: 0.1531 - accuracy: 0.9394 - val_loss: 0.2299 - val_accuracy: 0.9142 - lr: 9.7030e-04\n","Epoch 35/200\n","281/281 [==============================] - 31s 111ms/step - loss: 0.1464 - accuracy: 0.9389 - val_loss: 0.3275 - val_accuracy: 0.8663 - lr: 9.7030e-04\n","Epoch 36/200\n","281/281 [==============================] - 31s 112ms/step - loss: 0.1545 - accuracy: 0.9403 - val_loss: 0.3387 - val_accuracy: 0.8703 - lr: 9.6060e-04\n","Epoch 37/200\n","281/281 [==============================] - 32s 113ms/step - loss: 0.1428 - accuracy: 0.9440 - val_loss: 0.2064 - val_accuracy: 0.9142 - lr: 9.6060e-04\n","Epoch 38/200\n","281/281 [==============================] - 30s 104ms/step - loss: 0.1372 - accuracy: 0.9443 - val_loss: 0.2425 - val_accuracy: 0.9042 - lr: 9.6060e-04\n","Epoch 39/200\n","281/281 [==============================] - 30s 108ms/step - loss: 0.1417 - accuracy: 0.9451 - val_loss: 0.2449 - val_accuracy: 0.9222 - lr: 9.6060e-04\n","Epoch 40/200\n","281/281 [==============================] - 30s 106ms/step - loss: 0.1333 - accuracy: 0.9476 - val_loss: 0.1960 - val_accuracy: 0.9182 - lr: 9.6060e-04\n","Starting training on fold num: 2\n","Epoch 1/200\n","281/281 [==============================] - 53s 129ms/step - loss: 0.4977 - accuracy: 0.7657 - val_loss: 0.3902 - val_accuracy: 0.8144 - lr: 0.0010\n","Epoch 2/200\n","281/281 [==============================] - 33s 118ms/step - loss: 0.3768 - accuracy: 0.8343 - val_loss: 0.3552 - val_accuracy: 0.8303 - lr: 0.0010\n","Epoch 3/200\n","281/281 [==============================] - 34s 120ms/step - loss: 0.3471 - accuracy: 0.8485 - val_loss: 0.2904 - val_accuracy: 0.8703 - lr: 0.0010\n","Epoch 4/200\n","281/281 [==============================] - 31s 110ms/step - loss: 0.3080 - accuracy: 0.8630 - val_loss: 0.3365 - val_accuracy: 0.8503 - lr: 0.0010\n","Epoch 5/200\n","281/281 [==============================] - 34s 119ms/step - loss: 0.2951 - accuracy: 0.8743 - val_loss: 0.3095 - val_accuracy: 0.8782 - lr: 0.0010\n","Epoch 6/200\n","281/281 [==============================] - 34s 122ms/step - loss: 0.2856 - accuracy: 0.8812 - val_loss: 0.3003 - val_accuracy: 0.8902 - lr: 0.0010\n","Epoch 7/200\n","281/281 [==============================] - 32s 113ms/step - loss: 0.2773 - accuracy: 0.8852 - val_loss: 0.2576 - val_accuracy: 0.8822 - lr: 0.0010\n","Epoch 8/200\n","281/281 [==============================] - 29s 104ms/step - loss: 0.2602 - accuracy: 0.8927 - val_loss: 0.3300 - val_accuracy: 0.8762 - lr: 0.0010\n","Epoch 9/200\n","281/281 [==============================] - 32s 113ms/step - loss: 0.2493 - accuracy: 0.8952 - val_loss: 0.2733 - val_accuracy: 0.8802 - lr: 0.0010\n","Epoch 10/200\n","281/281 [==============================] - 33s 119ms/step - loss: 0.2343 - accuracy: 0.9027 - val_loss: 0.2575 - val_accuracy: 0.8822 - lr: 0.0010\n","Epoch 11/200\n","281/281 [==============================] - 31s 110ms/step - loss: 0.2276 - accuracy: 0.9023 - val_loss: 0.3065 - val_accuracy: 0.8683 - lr: 0.0010\n","Epoch 12/200\n","281/281 [==============================] - 32s 113ms/step - loss: 0.2324 - accuracy: 0.9081 - val_loss: 0.2705 - val_accuracy: 0.9002 - lr: 9.9000e-04\n","Epoch 13/200\n","281/281 [==============================] - 34s 122ms/step - loss: 0.2232 - accuracy: 0.9043 - val_loss: 0.2798 - val_accuracy: 0.8902 - lr: 9.9000e-04\n","Epoch 14/200\n","281/281 [==============================] - 33s 118ms/step - loss: 0.2140 - accuracy: 0.9136 - val_loss: 0.2773 - val_accuracy: 0.9002 - lr: 9.9000e-04\n","Epoch 15/200\n","281/281 [==============================] - 30s 106ms/step - loss: 0.2095 - accuracy: 0.9185 - val_loss: 0.2734 - val_accuracy: 0.8842 - lr: 9.9000e-04\n","Epoch 16/200\n","281/281 [==============================] - 31s 109ms/step - loss: 0.2028 - accuracy: 0.9192 - val_loss: 0.2557 - val_accuracy: 0.8922 - lr: 9.9000e-04\n","Epoch 17/200\n","281/281 [==============================] - 31s 111ms/step - loss: 0.2084 - accuracy: 0.9101 - val_loss: 0.2488 - val_accuracy: 0.9002 - lr: 9.9000e-04\n","Epoch 18/200\n","281/281 [==============================] - 31s 111ms/step - loss: 0.1834 - accuracy: 0.9241 - val_loss: 0.2688 - val_accuracy: 0.8922 - lr: 9.8010e-04\n","Epoch 19/200\n","281/281 [==============================] - 32s 113ms/step - loss: 0.1966 - accuracy: 0.9189 - val_loss: 0.2339 - val_accuracy: 0.9022 - lr: 9.8010e-04\n","Epoch 20/200\n","281/281 [==============================] - 30s 107ms/step - loss: 0.1928 - accuracy: 0.9254 - val_loss: 0.2499 - val_accuracy: 0.9062 - lr: 9.8010e-04\n","Epoch 21/200\n","281/281 [==============================] - 32s 114ms/step - loss: 0.1833 - accuracy: 0.9247 - val_loss: 0.2627 - val_accuracy: 0.8962 - lr: 9.8010e-04\n","Epoch 22/200\n","281/281 [==============================] - 32s 115ms/step - loss: 0.1809 - accuracy: 0.9252 - val_loss: 0.2831 - val_accuracy: 0.8902 - lr: 9.8010e-04\n","Epoch 23/200\n","281/281 [==============================] - 30s 108ms/step - loss: 0.1782 - accuracy: 0.9274 - val_loss: 0.2992 - val_accuracy: 0.8862 - lr: 9.8010e-04\n","Epoch 24/200\n","281/281 [==============================] - 32s 114ms/step - loss: 0.1725 - accuracy: 0.9267 - val_loss: 0.2690 - val_accuracy: 0.8962 - lr: 9.8010e-04\n","Epoch 25/200\n","281/281 [==============================] - 31s 110ms/step - loss: 0.1844 - accuracy: 0.9225 - val_loss: 0.2490 - val_accuracy: 0.9022 - lr: 9.8010e-04\n","Epoch 26/200\n","281/281 [==============================] - 29s 103ms/step - loss: 0.1621 - accuracy: 0.9378 - val_loss: 0.3835 - val_accuracy: 0.8782 - lr: 9.7030e-04\n","Epoch 27/200\n","281/281 [==============================] - 31s 110ms/step - loss: 0.1631 - accuracy: 0.9332 - val_loss: 0.3785 - val_accuracy: 0.8962 - lr: 9.7030e-04\n","Epoch 28/200\n","281/281 [==============================] - 41s 147ms/step - loss: 0.1695 - accuracy: 0.9372 - val_loss: 0.2839 - val_accuracy: 0.8942 - lr: 9.7030e-04\n","Epoch 29/200\n","281/281 [==============================] - 30s 106ms/step - loss: 0.1648 - accuracy: 0.9352 - val_loss: 0.2491 - val_accuracy: 0.9102 - lr: 9.7030e-04\n","Epoch 30/200\n","281/281 [==============================] - 33s 115ms/step - loss: 0.1577 - accuracy: 0.9363 - val_loss: 0.2402 - val_accuracy: 0.8902 - lr: 9.7030e-04\n","Epoch 31/200\n","281/281 [==============================] - 33s 119ms/step - loss: 0.1545 - accuracy: 0.9400 - val_loss: 0.2625 - val_accuracy: 0.9002 - lr: 9.7030e-04\n","Epoch 32/200\n","281/281 [==============================] - 31s 111ms/step - loss: 0.1463 - accuracy: 0.9405 - val_loss: 0.2432 - val_accuracy: 0.9022 - lr: 9.7030e-04\n","Epoch 33/200\n","281/281 [==============================] - 31s 110ms/step - loss: 0.1530 - accuracy: 0.9358 - val_loss: 0.3017 - val_accuracy: 0.8922 - lr: 9.7030e-04\n","Epoch 34/200\n","281/281 [==============================] - 28s 100ms/step - loss: 0.1500 - accuracy: 0.9416 - val_loss: 0.2805 - val_accuracy: 0.8882 - lr: 9.7030e-04\n","Epoch 35/200\n","281/281 [==============================] - 31s 110ms/step - loss: 0.1493 - accuracy: 0.9392 - val_loss: 0.2468 - val_accuracy: 0.9022 - lr: 9.6060e-04\n","Epoch 36/200\n","281/281 [==============================] - 31s 110ms/step - loss: 0.1470 - accuracy: 0.9400 - val_loss: 0.2346 - val_accuracy: 0.9002 - lr: 9.6060e-04\n","Epoch 37/200\n","281/281 [==============================] - 30s 106ms/step - loss: 0.1435 - accuracy: 0.9420 - val_loss: 0.2288 - val_accuracy: 0.8882 - lr: 9.6060e-04\n","Epoch 38/200\n","281/281 [==============================] - 28s 100ms/step - loss: 0.1344 - accuracy: 0.9465 - val_loss: 0.2725 - val_accuracy: 0.9042 - lr: 9.6060e-04\n","Epoch 39/200\n","281/281 [==============================] - 31s 111ms/step - loss: 0.1391 - accuracy: 0.9480 - val_loss: 0.2745 - val_accuracy: 0.9122 - lr: 9.6060e-04\n","Epoch 40/200\n","281/281 [==============================] - 31s 111ms/step - loss: 0.1301 - accuracy: 0.9491 - val_loss: 0.2687 - val_accuracy: 0.8802 - lr: 9.6060e-04\n","Epoch 41/200\n","281/281 [==============================] - 31s 108ms/step - loss: 0.1389 - accuracy: 0.9465 - val_loss: 0.2649 - val_accuracy: 0.8842 - lr: 9.6060e-04\n","Epoch 42/200\n","281/281 [==============================] - 31s 108ms/step - loss: 0.1360 - accuracy: 0.9443 - val_loss: 0.2638 - val_accuracy: 0.8962 - lr: 9.6060e-04\n","Epoch 43/200\n","281/281 [==============================] - 29s 104ms/step - loss: 0.1323 - accuracy: 0.9460 - val_loss: 0.2765 - val_accuracy: 0.8922 - lr: 9.6060e-04\n","Epoch 44/200\n","281/281 [==============================] - 29s 102ms/step - loss: 0.1264 - accuracy: 0.9494 - val_loss: 0.2825 - val_accuracy: 0.8822 - lr: 9.6060e-04\n","Epoch 45/200\n","281/281 [==============================] - 31s 111ms/step - loss: 0.1409 - accuracy: 0.9418 - val_loss: 0.2645 - val_accuracy: 0.8962 - lr: 9.5099e-04\n","Epoch 46/200\n","281/281 [==============================] - 31s 108ms/step - loss: 0.1261 - accuracy: 0.9458 - val_loss: 0.2332 - val_accuracy: 0.9002 - lr: 9.5099e-04\n","Epoch 47/200\n","281/281 [==============================] - 29s 105ms/step - loss: 0.1259 - accuracy: 0.9536 - val_loss: 0.2502 - val_accuracy: 0.9082 - lr: 9.5099e-04\n","Epoch 48/200\n","281/281 [==============================] - 30s 106ms/step - loss: 0.1167 - accuracy: 0.9534 - val_loss: 0.2306 - val_accuracy: 0.8962 - lr: 9.5099e-04\n","Epoch 49/200\n","281/281 [==============================] - 31s 110ms/step - loss: 0.1253 - accuracy: 0.9538 - val_loss: 0.2750 - val_accuracy: 0.8902 - lr: 9.5099e-04\n","Epoch 50/200\n","281/281 [==============================] - 29s 104ms/step - loss: 0.1236 - accuracy: 0.9516 - val_loss: 0.2554 - val_accuracy: 0.8942 - lr: 9.4148e-04\n","Epoch 51/200\n","281/281 [==============================] - 30s 105ms/step - loss: 0.1214 - accuracy: 0.9538 - val_loss: 0.3380 - val_accuracy: 0.8862 - lr: 9.4148e-04\n","Epoch 52/200\n","281/281 [==============================] - 32s 113ms/step - loss: 0.1275 - accuracy: 0.9514 - val_loss: 0.2924 - val_accuracy: 0.9062 - lr: 9.4148e-04\n","Epoch 53/200\n","281/281 [==============================] - 29s 104ms/step - loss: 0.1236 - accuracy: 0.9516 - val_loss: 0.2904 - val_accuracy: 0.9002 - lr: 9.4148e-04\n","Epoch 54/200\n","281/281 [==============================] - 31s 110ms/step - loss: 0.1200 - accuracy: 0.9536 - val_loss: 0.3018 - val_accuracy: 0.8982 - lr: 9.4148e-04\n","Starting training on fold num: 3\n","Epoch 1/200\n","281/281 [==============================] - 53s 128ms/step - loss: 0.5156 - accuracy: 0.7653 - val_loss: 0.4252 - val_accuracy: 0.8144 - lr: 0.0010\n","Epoch 2/200\n","281/281 [==============================] - 32s 112ms/step - loss: 0.3684 - accuracy: 0.8361 - val_loss: 0.3460 - val_accuracy: 0.8463 - lr: 0.0010\n","Epoch 3/200\n","281/281 [==============================] - 32s 113ms/step - loss: 0.3401 - accuracy: 0.8457 - val_loss: 0.3257 - val_accuracy: 0.8543 - lr: 0.0010\n","Epoch 4/200\n","281/281 [==============================] - 31s 111ms/step - loss: 0.3123 - accuracy: 0.8650 - val_loss: 0.3240 - val_accuracy: 0.8523 - lr: 0.0010\n","Epoch 5/200\n","281/281 [==============================] - 31s 109ms/step - loss: 0.2961 - accuracy: 0.8708 - val_loss: 0.3349 - val_accuracy: 0.8363 - lr: 0.0010\n","Epoch 6/200\n","281/281 [==============================] - 29s 103ms/step - loss: 0.2761 - accuracy: 0.8856 - val_loss: 0.3163 - val_accuracy: 0.8683 - lr: 0.0010\n","Epoch 7/200\n","281/281 [==============================] - 30s 106ms/step - loss: 0.2693 - accuracy: 0.8852 - val_loss: 0.3948 - val_accuracy: 0.8104 - lr: 0.0010\n","Epoch 8/200\n","281/281 [==============================] - 32s 113ms/step - loss: 0.2574 - accuracy: 0.8910 - val_loss: 0.3161 - val_accuracy: 0.8723 - lr: 0.0010\n","Epoch 9/200\n","281/281 [==============================] - 28s 101ms/step - loss: 0.2481 - accuracy: 0.8952 - val_loss: 0.3324 - val_accuracy: 0.8583 - lr: 0.0010\n","Epoch 10/200\n","281/281 [==============================] - 30s 108ms/step - loss: 0.2325 - accuracy: 0.9041 - val_loss: 0.2943 - val_accuracy: 0.8723 - lr: 0.0010\n","Epoch 11/200\n","281/281 [==============================] - 31s 109ms/step - loss: 0.2342 - accuracy: 0.9032 - val_loss: 0.3374 - val_accuracy: 0.8483 - lr: 0.0010\n","Epoch 12/200\n","281/281 [==============================] - 28s 101ms/step - loss: 0.2317 - accuracy: 0.9052 - val_loss: 0.2785 - val_accuracy: 0.8782 - lr: 0.0010\n","Epoch 13/200\n","281/281 [==============================] - 31s 110ms/step - loss: 0.2164 - accuracy: 0.9112 - val_loss: 0.2832 - val_accuracy: 0.8762 - lr: 0.0010\n","Epoch 14/200\n","281/281 [==============================] - 29s 102ms/step - loss: 0.2079 - accuracy: 0.9187 - val_loss: 0.3061 - val_accuracy: 0.8703 - lr: 0.0010\n","Epoch 15/200\n","281/281 [==============================] - 30s 106ms/step - loss: 0.2285 - accuracy: 0.9032 - val_loss: 0.3419 - val_accuracy: 0.8583 - lr: 0.0010\n","Epoch 16/200\n","281/281 [==============================] - 29s 104ms/step - loss: 0.2201 - accuracy: 0.9105 - val_loss: 0.3075 - val_accuracy: 0.8882 - lr: 0.0010\n","Epoch 17/200\n","281/281 [==============================] - 30s 106ms/step - loss: 0.1990 - accuracy: 0.9174 - val_loss: 0.3201 - val_accuracy: 0.8543 - lr: 0.0010\n","Epoch 18/200\n","281/281 [==============================] - 30s 107ms/step - loss: 0.1879 - accuracy: 0.9201 - val_loss: 0.2814 - val_accuracy: 0.8882 - lr: 0.0010\n","Epoch 19/200\n","281/281 [==============================] - 30s 108ms/step - loss: 0.1969 - accuracy: 0.9172 - val_loss: 0.2699 - val_accuracy: 0.9022 - lr: 0.0010\n","Epoch 20/200\n","281/281 [==============================] - 31s 110ms/step - loss: 0.1853 - accuracy: 0.9201 - val_loss: 0.2776 - val_accuracy: 0.9002 - lr: 0.0010\n","Epoch 21/200\n","281/281 [==============================] - 28s 99ms/step - loss: 0.1884 - accuracy: 0.9274 - val_loss: 0.2781 - val_accuracy: 0.8802 - lr: 0.0010\n","Epoch 22/200\n","281/281 [==============================] - 32s 113ms/step - loss: 0.1958 - accuracy: 0.9192 - val_loss: 0.2709 - val_accuracy: 0.8962 - lr: 0.0010\n","Epoch 23/200\n","281/281 [==============================] - 31s 112ms/step - loss: 0.1750 - accuracy: 0.9287 - val_loss: 0.2967 - val_accuracy: 0.8862 - lr: 0.0010\n","Epoch 24/200\n","281/281 [==============================] - 30s 107ms/step - loss: 0.1720 - accuracy: 0.9276 - val_loss: 0.3042 - val_accuracy: 0.8922 - lr: 0.0010\n","Epoch 25/200\n","281/281 [==============================] - 31s 110ms/step - loss: 0.1792 - accuracy: 0.9229 - val_loss: 0.2908 - val_accuracy: 0.8882 - lr: 9.9000e-04\n","Epoch 26/200\n","281/281 [==============================] - 30s 105ms/step - loss: 0.1709 - accuracy: 0.9312 - val_loss: 0.3197 - val_accuracy: 0.8862 - lr: 9.9000e-04\n","Epoch 27/200\n","281/281 [==============================] - 31s 109ms/step - loss: 0.1704 - accuracy: 0.9314 - val_loss: 0.3146 - val_accuracy: 0.8802 - lr: 9.9000e-04\n","Epoch 28/200\n","281/281 [==============================] - 30s 108ms/step - loss: 0.1554 - accuracy: 0.9369 - val_loss: 0.2768 - val_accuracy: 0.8902 - lr: 9.9000e-04\n","Epoch 29/200\n","281/281 [==============================] - 32s 115ms/step - loss: 0.1650 - accuracy: 0.9325 - val_loss: 0.3080 - val_accuracy: 0.8962 - lr: 9.9000e-04\n","Epoch 30/200\n","281/281 [==============================] - 29s 105ms/step - loss: 0.1676 - accuracy: 0.9318 - val_loss: 0.2641 - val_accuracy: 0.9002 - lr: 9.8010e-04\n","Epoch 31/200\n","281/281 [==============================] - 31s 109ms/step - loss: 0.1516 - accuracy: 0.9378 - val_loss: 0.2849 - val_accuracy: 0.8942 - lr: 9.8010e-04\n","Epoch 32/200\n","281/281 [==============================] - 30s 105ms/step - loss: 0.1612 - accuracy: 0.9374 - val_loss: 0.2251 - val_accuracy: 0.9182 - lr: 9.8010e-04\n","Epoch 33/200\n","281/281 [==============================] - 31s 109ms/step - loss: 0.1459 - accuracy: 0.9449 - val_loss: 0.2461 - val_accuracy: 0.9122 - lr: 9.8010e-04\n","Epoch 34/200\n","281/281 [==============================] - 31s 110ms/step - loss: 0.1554 - accuracy: 0.9365 - val_loss: 0.3154 - val_accuracy: 0.8962 - lr: 9.8010e-04\n","Epoch 35/200\n","281/281 [==============================] - 29s 104ms/step - loss: 0.1479 - accuracy: 0.9416 - val_loss: 0.2786 - val_accuracy: 0.9102 - lr: 9.8010e-04\n","Epoch 36/200\n","281/281 [==============================] - 31s 110ms/step - loss: 0.1412 - accuracy: 0.9436 - val_loss: 0.3119 - val_accuracy: 0.9062 - lr: 9.8010e-04\n","Epoch 37/200\n","281/281 [==============================] - 31s 109ms/step - loss: 0.1537 - accuracy: 0.9380 - val_loss: 0.3531 - val_accuracy: 0.8683 - lr: 9.8010e-04\n","Epoch 38/200\n","281/281 [==============================] - 32s 115ms/step - loss: 0.1424 - accuracy: 0.9420 - val_loss: 0.2582 - val_accuracy: 0.9042 - lr: 9.7030e-04\n","Epoch 39/200\n","281/281 [==============================] - 29s 103ms/step - loss: 0.1478 - accuracy: 0.9436 - val_loss: 0.2434 - val_accuracy: 0.9062 - lr: 9.7030e-04\n","Epoch 40/200\n","281/281 [==============================] - 33s 116ms/step - loss: 0.1421 - accuracy: 0.9427 - val_loss: 0.2798 - val_accuracy: 0.9002 - lr: 9.7030e-04\n","Epoch 41/200\n","281/281 [==============================] - 31s 109ms/step - loss: 0.1409 - accuracy: 0.9465 - val_loss: 0.2588 - val_accuracy: 0.9102 - lr: 9.7030e-04\n","Epoch 42/200\n","281/281 [==============================] - 29s 101ms/step - loss: 0.1366 - accuracy: 0.9436 - val_loss: 0.2861 - val_accuracy: 0.8962 - lr: 9.7030e-04\n","Epoch 43/200\n","281/281 [==============================] - 32s 113ms/step - loss: 0.1447 - accuracy: 0.9431 - val_loss: 0.3410 - val_accuracy: 0.8643 - lr: 9.6060e-04\n","Epoch 44/200\n","281/281 [==============================] - 31s 109ms/step - loss: 0.1318 - accuracy: 0.9489 - val_loss: 0.3089 - val_accuracy: 0.8842 - lr: 9.6060e-04\n","Epoch 45/200\n","281/281 [==============================] - 31s 108ms/step - loss: 0.1230 - accuracy: 0.9534 - val_loss: 0.2971 - val_accuracy: 0.8962 - lr: 9.6060e-04\n","Epoch 46/200\n","281/281 [==============================] - 30s 107ms/step - loss: 0.1249 - accuracy: 0.9516 - val_loss: 0.4424 - val_accuracy: 0.8762 - lr: 9.6060e-04\n","Epoch 47/200\n","281/281 [==============================] - 33s 118ms/step - loss: 0.1246 - accuracy: 0.9505 - val_loss: 0.3233 - val_accuracy: 0.8902 - lr: 9.6060e-04\n","Starting training on fold num: 4\n","Epoch 1/200\n","281/281 [==============================] - 53s 126ms/step - loss: 0.4929 - accuracy: 0.7639 - val_loss: 0.3902 - val_accuracy: 0.8244 - lr: 0.0010\n","Epoch 2/200\n","281/281 [==============================] - 32s 112ms/step - loss: 0.3803 - accuracy: 0.8312 - val_loss: 0.3291 - val_accuracy: 0.8743 - lr: 0.0010\n","Epoch 3/200\n","281/281 [==============================] - 30s 105ms/step - loss: 0.3429 - accuracy: 0.8461 - val_loss: 0.3370 - val_accuracy: 0.8563 - lr: 0.0010\n","Epoch 4/200\n","281/281 [==============================] - 32s 115ms/step - loss: 0.3139 - accuracy: 0.8665 - val_loss: 0.2987 - val_accuracy: 0.8743 - lr: 0.0010\n","Epoch 5/200\n","281/281 [==============================] - 32s 114ms/step - loss: 0.2956 - accuracy: 0.8730 - val_loss: 0.2770 - val_accuracy: 0.8802 - lr: 0.0010\n","Epoch 6/200\n","281/281 [==============================] - 31s 109ms/step - loss: 0.2972 - accuracy: 0.8739 - val_loss: 0.3197 - val_accuracy: 0.8523 - lr: 0.0010\n","Epoch 7/200\n","281/281 [==============================] - 32s 113ms/step - loss: 0.2627 - accuracy: 0.8874 - val_loss: 0.2747 - val_accuracy: 0.8842 - lr: 0.0010\n","Epoch 8/200\n","281/281 [==============================] - 32s 114ms/step - loss: 0.2597 - accuracy: 0.8901 - val_loss: 0.2506 - val_accuracy: 0.8962 - lr: 0.0010\n","Epoch 9/200\n","281/281 [==============================] - 31s 111ms/step - loss: 0.2567 - accuracy: 0.8941 - val_loss: 0.2848 - val_accuracy: 0.8723 - lr: 0.0010\n","Epoch 10/200\n","281/281 [==============================] - 31s 111ms/step - loss: 0.2475 - accuracy: 0.8963 - val_loss: 0.2896 - val_accuracy: 0.8782 - lr: 0.0010\n","Epoch 11/200\n","281/281 [==============================] - 32s 113ms/step - loss: 0.2242 - accuracy: 0.9143 - val_loss: 0.2737 - val_accuracy: 0.8822 - lr: 0.0010\n","Epoch 12/200\n","281/281 [==============================] - 31s 111ms/step - loss: 0.2376 - accuracy: 0.9027 - val_loss: 0.2464 - val_accuracy: 0.9082 - lr: 0.0010\n","Epoch 13/200\n","281/281 [==============================] - 29s 104ms/step - loss: 0.2150 - accuracy: 0.9076 - val_loss: 0.2442 - val_accuracy: 0.9002 - lr: 0.0010\n","Epoch 14/200\n","281/281 [==============================] - 31s 110ms/step - loss: 0.2024 - accuracy: 0.9178 - val_loss: 0.2288 - val_accuracy: 0.9142 - lr: 0.0010\n","Epoch 15/200\n","281/281 [==============================] - 33s 116ms/step - loss: 0.2201 - accuracy: 0.9047 - val_loss: 0.2494 - val_accuracy: 0.8982 - lr: 0.0010\n","Epoch 16/200\n","281/281 [==============================] - 30s 105ms/step - loss: 0.2155 - accuracy: 0.9129 - val_loss: 0.2768 - val_accuracy: 0.8882 - lr: 0.0010\n","Epoch 17/200\n","281/281 [==============================] - 32s 112ms/step - loss: 0.1977 - accuracy: 0.9203 - val_loss: 0.2688 - val_accuracy: 0.8802 - lr: 0.0010\n","Epoch 18/200\n","281/281 [==============================] - 33s 117ms/step - loss: 0.2043 - accuracy: 0.9147 - val_loss: 0.2720 - val_accuracy: 0.8802 - lr: 0.0010\n","Epoch 19/200\n","281/281 [==============================] - 32s 112ms/step - loss: 0.1994 - accuracy: 0.9161 - val_loss: 0.2513 - val_accuracy: 0.9002 - lr: 0.0010\n","Epoch 20/200\n","281/281 [==============================] - 32s 112ms/step - loss: 0.1900 - accuracy: 0.9256 - val_loss: 0.2843 - val_accuracy: 0.8962 - lr: 9.9000e-04\n","Epoch 21/200\n","281/281 [==============================] - 33s 115ms/step - loss: 0.1884 - accuracy: 0.9225 - val_loss: 0.3216 - val_accuracy: 0.8743 - lr: 9.9000e-04\n","Epoch 22/200\n","281/281 [==============================] - 32s 112ms/step - loss: 0.1848 - accuracy: 0.9232 - val_loss: 0.2192 - val_accuracy: 0.9022 - lr: 9.9000e-04\n","Epoch 23/200\n","281/281 [==============================] - 30s 105ms/step - loss: 0.1676 - accuracy: 0.9320 - val_loss: 0.2832 - val_accuracy: 0.8762 - lr: 9.9000e-04\n","Epoch 24/200\n","281/281 [==============================] - 32s 112ms/step - loss: 0.1866 - accuracy: 0.9225 - val_loss: 0.2851 - val_accuracy: 0.8762 - lr: 9.9000e-04\n","Epoch 25/200\n","281/281 [==============================] - 33s 116ms/step - loss: 0.1729 - accuracy: 0.9272 - val_loss: 0.2401 - val_accuracy: 0.9022 - lr: 9.8010e-04\n","Epoch 26/200\n","281/281 [==============================] - 30s 107ms/step - loss: 0.1722 - accuracy: 0.9305 - val_loss: 0.2467 - val_accuracy: 0.8982 - lr: 9.8010e-04\n","Epoch 27/200\n","281/281 [==============================] - 33s 117ms/step - loss: 0.1740 - accuracy: 0.9300 - val_loss: 0.2659 - val_accuracy: 0.8942 - lr: 9.8010e-04\n","Epoch 28/200\n","281/281 [==============================] - 31s 111ms/step - loss: 0.1638 - accuracy: 0.9356 - val_loss: 0.2661 - val_accuracy: 0.9062 - lr: 9.8010e-04\n","Epoch 29/200\n","281/281 [==============================] - 31s 112ms/step - loss: 0.1626 - accuracy: 0.9349 - val_loss: 0.2837 - val_accuracy: 0.8802 - lr: 9.8010e-04\n","Starting training on fold num: 5\n","Epoch 1/200\n","281/281 [==============================] - 65s 170ms/step - loss: 0.5156 - accuracy: 0.7567 - val_loss: 0.3464 - val_accuracy: 0.8620 - lr: 0.0010\n","Epoch 2/200\n","281/281 [==============================] - 31s 109ms/step - loss: 0.3815 - accuracy: 0.8286 - val_loss: 0.3592 - val_accuracy: 0.8260 - lr: 0.0010\n","Epoch 3/200\n","281/281 [==============================] - 32s 113ms/step - loss: 0.3445 - accuracy: 0.8459 - val_loss: 0.3511 - val_accuracy: 0.8440 - lr: 0.0010\n","Epoch 4/200\n","281/281 [==============================] - 30s 106ms/step - loss: 0.3211 - accuracy: 0.8615 - val_loss: 0.3132 - val_accuracy: 0.8620 - lr: 0.0010\n","Epoch 5/200\n","281/281 [==============================] - 32s 114ms/step - loss: 0.3047 - accuracy: 0.8681 - val_loss: 0.3740 - val_accuracy: 0.8380 - lr: 0.0010\n","Epoch 6/200\n","281/281 [==============================] - 30s 107ms/step - loss: 0.2868 - accuracy: 0.8774 - val_loss: 0.3016 - val_accuracy: 0.8600 - lr: 0.0010\n","Epoch 7/200\n","281/281 [==============================] - 32s 114ms/step - loss: 0.2798 - accuracy: 0.8799 - val_loss: 0.3465 - val_accuracy: 0.8680 - lr: 9.9000e-04\n","Epoch 8/200\n","281/281 [==============================] - 33s 117ms/step - loss: 0.2487 - accuracy: 0.8932 - val_loss: 0.3005 - val_accuracy: 0.8780 - lr: 9.9000e-04\n","Epoch 9/200\n","281/281 [==============================] - 31s 108ms/step - loss: 0.2419 - accuracy: 0.8959 - val_loss: 0.2964 - val_accuracy: 0.8780 - lr: 9.9000e-04\n","Epoch 10/200\n","281/281 [==============================] - 32s 115ms/step - loss: 0.2473 - accuracy: 0.8930 - val_loss: 0.2679 - val_accuracy: 0.8920 - lr: 9.9000e-04\n","Epoch 11/200\n","281/281 [==============================] - 31s 108ms/step - loss: 0.2427 - accuracy: 0.8932 - val_loss: 0.2723 - val_accuracy: 0.8840 - lr: 9.9000e-04\n","Epoch 12/200\n","281/281 [==============================] - 30s 105ms/step - loss: 0.2301 - accuracy: 0.9036 - val_loss: 0.2619 - val_accuracy: 0.8900 - lr: 9.9000e-04\n","Epoch 13/200\n","281/281 [==============================] - 33s 116ms/step - loss: 0.2324 - accuracy: 0.9045 - val_loss: 0.4030 - val_accuracy: 0.8600 - lr: 9.9000e-04\n","Epoch 14/200\n","281/281 [==============================] - 33s 118ms/step - loss: 0.2253 - accuracy: 0.9052 - val_loss: 0.2553 - val_accuracy: 0.8960 - lr: 9.9000e-04\n","Epoch 15/200\n","281/281 [==============================] - 30s 106ms/step - loss: 0.2098 - accuracy: 0.9112 - val_loss: 0.3282 - val_accuracy: 0.8700 - lr: 9.9000e-04\n","Epoch 16/200\n","281/281 [==============================] - 31s 111ms/step - loss: 0.2020 - accuracy: 0.9141 - val_loss: 0.2682 - val_accuracy: 0.8880 - lr: 9.9000e-04\n","Epoch 17/200\n","281/281 [==============================] - 30s 105ms/step - loss: 0.2061 - accuracy: 0.9147 - val_loss: 0.3141 - val_accuracy: 0.8880 - lr: 9.9000e-04\n","Epoch 18/200\n","281/281 [==============================] - 31s 111ms/step - loss: 0.1976 - accuracy: 0.9192 - val_loss: 0.2780 - val_accuracy: 0.8860 - lr: 9.9000e-04\n","Epoch 19/200\n","281/281 [==============================] - 30s 108ms/step - loss: 0.1927 - accuracy: 0.9218 - val_loss: 0.2827 - val_accuracy: 0.8800 - lr: 9.9000e-04\n","Epoch 20/200\n","281/281 [==============================] - 34s 119ms/step - loss: 0.1895 - accuracy: 0.9172 - val_loss: 0.2345 - val_accuracy: 0.9000 - lr: 9.8010e-04\n","Epoch 21/200\n","281/281 [==============================] - 30s 106ms/step - loss: 0.1828 - accuracy: 0.9256 - val_loss: 0.3022 - val_accuracy: 0.8900 - lr: 9.8010e-04\n","Epoch 22/200\n","281/281 [==============================] - 32s 115ms/step - loss: 0.1765 - accuracy: 0.9285 - val_loss: 0.2824 - val_accuracy: 0.8940 - lr: 9.8010e-04\n","Epoch 23/200\n","281/281 [==============================] - 32s 114ms/step - loss: 0.1699 - accuracy: 0.9278 - val_loss: 0.2758 - val_accuracy: 0.9000 - lr: 9.8010e-04\n","Epoch 24/200\n","281/281 [==============================] - 30s 106ms/step - loss: 0.1791 - accuracy: 0.9270 - val_loss: 0.2935 - val_accuracy: 0.8840 - lr: 9.8010e-04\n","Epoch 25/200\n","281/281 [==============================] - 32s 114ms/step - loss: 0.1775 - accuracy: 0.9265 - val_loss: 0.2889 - val_accuracy: 0.8840 - lr: 9.8010e-04\n","Epoch 26/200\n","281/281 [==============================] - 33s 118ms/step - loss: 0.1657 - accuracy: 0.9354 - val_loss: 0.3080 - val_accuracy: 0.8700 - lr: 9.7030e-04\n","Epoch 27/200\n","281/281 [==============================] - 31s 110ms/step - loss: 0.1678 - accuracy: 0.9354 - val_loss: 0.2531 - val_accuracy: 0.8980 - lr: 9.7030e-04\n","Epoch 28/200\n","281/281 [==============================] - 33s 117ms/step - loss: 0.1643 - accuracy: 0.9354 - val_loss: 0.2507 - val_accuracy: 0.8940 - lr: 9.7030e-04\n","Epoch 29/200\n","281/281 [==============================] - 31s 110ms/step - loss: 0.1627 - accuracy: 0.9323 - val_loss: 0.2799 - val_accuracy: 0.8880 - lr: 9.7030e-04\n","Epoch 30/200\n","281/281 [==============================] - 33s 118ms/step - loss: 0.1519 - accuracy: 0.9385 - val_loss: 0.3473 - val_accuracy: 0.8660 - lr: 9.7030e-04\n","Epoch 31/200\n","281/281 [==============================] - 30s 107ms/step - loss: 0.1492 - accuracy: 0.9381 - val_loss: 0.2866 - val_accuracy: 0.8720 - lr: 9.6060e-04\n","Epoch 32/200\n","281/281 [==============================] - 33s 117ms/step - loss: 0.1632 - accuracy: 0.9336 - val_loss: 0.3811 - val_accuracy: 0.8640 - lr: 9.6060e-04\n","Epoch 33/200\n","281/281 [==============================] - 32s 112ms/step - loss: 0.1522 - accuracy: 0.9374 - val_loss: 0.3112 - val_accuracy: 0.8820 - lr: 9.6060e-04\n","Epoch 34/200\n","281/281 [==============================] - 30s 107ms/step - loss: 0.1534 - accuracy: 0.9383 - val_loss: 0.3344 - val_accuracy: 0.8880 - lr: 9.6060e-04\n","Epoch 35/200\n","281/281 [==============================] - 31s 111ms/step - loss: 0.1514 - accuracy: 0.9394 - val_loss: 0.2848 - val_accuracy: 0.8780 - lr: 9.6060e-04\n","Starting training on fold num: 6\n","Epoch 1/200\n","281/281 [==============================] - 53s 132ms/step - loss: 0.5010 - accuracy: 0.7649 - val_loss: 0.3708 - val_accuracy: 0.8180 - lr: 0.0010\n","Epoch 2/200\n","281/281 [==============================] - 32s 113ms/step - loss: 0.3747 - accuracy: 0.8350 - val_loss: 0.3129 - val_accuracy: 0.8620 - lr: 0.0010\n","Epoch 3/200\n","281/281 [==============================] - 33s 118ms/step - loss: 0.3289 - accuracy: 0.8597 - val_loss: 0.3117 - val_accuracy: 0.8880 - lr: 0.0010\n","Epoch 4/200\n","281/281 [==============================] - 32s 112ms/step - loss: 0.3046 - accuracy: 0.8699 - val_loss: 0.2911 - val_accuracy: 0.8780 - lr: 0.0010\n","Epoch 5/200\n","281/281 [==============================] - 29s 102ms/step - loss: 0.2983 - accuracy: 0.8672 - val_loss: 0.2963 - val_accuracy: 0.8660 - lr: 0.0010\n","Epoch 6/200\n","281/281 [==============================] - 33s 117ms/step - loss: 0.2805 - accuracy: 0.8781 - val_loss: 0.2711 - val_accuracy: 0.8880 - lr: 0.0010\n","Epoch 7/200\n","281/281 [==============================] - 31s 111ms/step - loss: 0.2765 - accuracy: 0.8837 - val_loss: 0.2788 - val_accuracy: 0.8820 - lr: 0.0010\n","Epoch 8/200\n","281/281 [==============================] - 31s 109ms/step - loss: 0.2663 - accuracy: 0.8837 - val_loss: 0.2755 - val_accuracy: 0.8800 - lr: 0.0010\n","Epoch 9/200\n","281/281 [==============================] - 32s 114ms/step - loss: 0.2406 - accuracy: 0.8972 - val_loss: 0.2963 - val_accuracy: 0.8700 - lr: 9.9000e-04\n","Epoch 10/200\n","281/281 [==============================] - 30s 106ms/step - loss: 0.2495 - accuracy: 0.8974 - val_loss: 0.2894 - val_accuracy: 0.8680 - lr: 9.9000e-04\n","Epoch 11/200\n","281/281 [==============================] - 33s 116ms/step - loss: 0.2395 - accuracy: 0.8981 - val_loss: 0.2913 - val_accuracy: 0.8680 - lr: 9.9000e-04\n","Epoch 12/200\n","281/281 [==============================] - 31s 109ms/step - loss: 0.2352 - accuracy: 0.8985 - val_loss: 0.2309 - val_accuracy: 0.9020 - lr: 9.9000e-04\n","Epoch 13/200\n","281/281 [==============================] - 32s 112ms/step - loss: 0.2316 - accuracy: 0.9008 - val_loss: 0.2778 - val_accuracy: 0.8900 - lr: 9.9000e-04\n","Epoch 14/200\n","281/281 [==============================] - 32s 115ms/step - loss: 0.2223 - accuracy: 0.9112 - val_loss: 0.2758 - val_accuracy: 0.8940 - lr: 9.9000e-04\n","Epoch 15/200\n","281/281 [==============================] - 32s 114ms/step - loss: 0.2223 - accuracy: 0.9099 - val_loss: 0.2432 - val_accuracy: 0.9060 - lr: 9.9000e-04\n","Epoch 16/200\n","281/281 [==============================] - 30s 106ms/step - loss: 0.2095 - accuracy: 0.9103 - val_loss: 0.2719 - val_accuracy: 0.8720 - lr: 9.9000e-04\n","Epoch 17/200\n","281/281 [==============================] - 34s 119ms/step - loss: 0.2019 - accuracy: 0.9190 - val_loss: 0.2449 - val_accuracy: 0.8960 - lr: 9.9000e-04\n","Epoch 18/200\n","281/281 [==============================] - 32s 114ms/step - loss: 0.2011 - accuracy: 0.9185 - val_loss: 0.2532 - val_accuracy: 0.8860 - lr: 9.9000e-04\n","Epoch 19/200\n","281/281 [==============================] - 33s 116ms/step - loss: 0.1793 - accuracy: 0.9274 - val_loss: 0.3600 - val_accuracy: 0.8680 - lr: 9.9000e-04\n","Epoch 20/200\n","281/281 [==============================] - 31s 111ms/step - loss: 0.1841 - accuracy: 0.9230 - val_loss: 0.3014 - val_accuracy: 0.8800 - lr: 9.9000e-04\n","Epoch 21/200\n","281/281 [==============================] - 32s 113ms/step - loss: 0.1897 - accuracy: 0.9234 - val_loss: 0.2506 - val_accuracy: 0.8920 - lr: 9.8010e-04\n","Epoch 22/200\n","281/281 [==============================] - 32s 115ms/step - loss: 0.1844 - accuracy: 0.9225 - val_loss: 0.2913 - val_accuracy: 0.8680 - lr: 9.8010e-04\n","Epoch 23/200\n","281/281 [==============================] - 30s 107ms/step - loss: 0.1800 - accuracy: 0.9296 - val_loss: 0.2403 - val_accuracy: 0.8980 - lr: 9.8010e-04\n","Epoch 24/200\n","281/281 [==============================] - 31s 111ms/step - loss: 0.1695 - accuracy: 0.9314 - val_loss: 0.2655 - val_accuracy: 0.8920 - lr: 9.8010e-04\n","Epoch 25/200\n","281/281 [==============================] - 34s 120ms/step - loss: 0.1690 - accuracy: 0.9287 - val_loss: 0.2385 - val_accuracy: 0.8900 - lr: 9.8010e-04\n","Epoch 26/200\n","281/281 [==============================] - 32s 114ms/step - loss: 0.1604 - accuracy: 0.9332 - val_loss: 0.2556 - val_accuracy: 0.8940 - lr: 9.7030e-04\n","Epoch 27/200\n","281/281 [==============================] - 29s 105ms/step - loss: 0.1595 - accuracy: 0.9367 - val_loss: 0.3004 - val_accuracy: 0.8700 - lr: 9.7030e-04\n","Epoch 28/200\n","281/281 [==============================] - 32s 114ms/step - loss: 0.1752 - accuracy: 0.9316 - val_loss: 0.2807 - val_accuracy: 0.8860 - lr: 9.7030e-04\n","Epoch 29/200\n","281/281 [==============================] - 31s 109ms/step - loss: 0.1772 - accuracy: 0.9332 - val_loss: 0.2510 - val_accuracy: 0.9000 - lr: 9.7030e-04\n","Epoch 30/200\n","281/281 [==============================] - 29s 103ms/step - loss: 0.1536 - accuracy: 0.9363 - val_loss: 0.2933 - val_accuracy: 0.8680 - lr: 9.7030e-04\n","Starting training on fold num: 7\n","Epoch 1/200\n","281/281 [==============================] - 54s 131ms/step - loss: 0.4903 - accuracy: 0.7733 - val_loss: 0.3474 - val_accuracy: 0.8540 - lr: 0.0010\n","Epoch 2/200\n","281/281 [==============================] - 32s 113ms/step - loss: 0.3832 - accuracy: 0.8264 - val_loss: 0.3448 - val_accuracy: 0.8420 - lr: 0.0010\n","Epoch 3/200\n","281/281 [==============================] - 30s 105ms/step - loss: 0.3476 - accuracy: 0.8441 - val_loss: 0.3137 - val_accuracy: 0.8580 - lr: 0.0010\n","Epoch 4/200\n","281/281 [==============================] - 32s 115ms/step - loss: 0.3142 - accuracy: 0.8652 - val_loss: 0.3101 - val_accuracy: 0.8800 - lr: 0.0010\n","Epoch 5/200\n","281/281 [==============================] - 30s 106ms/step - loss: 0.2957 - accuracy: 0.8726 - val_loss: 0.2479 - val_accuracy: 0.8880 - lr: 0.0010\n","Epoch 6/200\n","281/281 [==============================] - 31s 108ms/step - loss: 0.2868 - accuracy: 0.8763 - val_loss: 0.2480 - val_accuracy: 0.8900 - lr: 0.0010\n","Epoch 7/200\n","281/281 [==============================] - 31s 111ms/step - loss: 0.2615 - accuracy: 0.8948 - val_loss: 0.3144 - val_accuracy: 0.8620 - lr: 0.0010\n","Epoch 8/200\n","281/281 [==============================] - 32s 114ms/step - loss: 0.2686 - accuracy: 0.8863 - val_loss: 0.2621 - val_accuracy: 0.8980 - lr: 0.0010\n","Epoch 9/200\n","281/281 [==============================] - 30s 106ms/step - loss: 0.2570 - accuracy: 0.8905 - val_loss: 0.3237 - val_accuracy: 0.8860 - lr: 0.0010\n","Epoch 10/200\n","281/281 [==============================] - 31s 111ms/step - loss: 0.2382 - accuracy: 0.8974 - val_loss: 0.2611 - val_accuracy: 0.8780 - lr: 0.0010\n","Epoch 11/200\n","281/281 [==============================] - 31s 111ms/step - loss: 0.2285 - accuracy: 0.9061 - val_loss: 0.3202 - val_accuracy: 0.8740 - lr: 0.0010\n","Epoch 12/200\n","281/281 [==============================] - 29s 104ms/step - loss: 0.2322 - accuracy: 0.9034 - val_loss: 0.2654 - val_accuracy: 0.8940 - lr: 0.0010\n","Epoch 13/200\n","281/281 [==============================] - 32s 114ms/step - loss: 0.2183 - accuracy: 0.9105 - val_loss: 0.2293 - val_accuracy: 0.9020 - lr: 0.0010\n","Epoch 14/200\n","281/281 [==============================] - 29s 102ms/step - loss: 0.2092 - accuracy: 0.9105 - val_loss: 0.2678 - val_accuracy: 0.8820 - lr: 0.0010\n","Epoch 15/200\n","281/281 [==============================] - 32s 113ms/step - loss: 0.2058 - accuracy: 0.9145 - val_loss: 0.2580 - val_accuracy: 0.8920 - lr: 0.0010\n","Epoch 16/200\n","281/281 [==============================] - 32s 112ms/step - loss: 0.2156 - accuracy: 0.9096 - val_loss: 0.2832 - val_accuracy: 0.8840 - lr: 0.0010\n","Epoch 17/200\n","281/281 [==============================] - 30s 107ms/step - loss: 0.2083 - accuracy: 0.9121 - val_loss: 0.2461 - val_accuracy: 0.8900 - lr: 0.0010\n","Epoch 18/200\n","281/281 [==============================] - 29s 104ms/step - loss: 0.2008 - accuracy: 0.9185 - val_loss: 0.3277 - val_accuracy: 0.8740 - lr: 0.0010\n","Epoch 19/200\n","281/281 [==============================] - 31s 111ms/step - loss: 0.1874 - accuracy: 0.9261 - val_loss: 0.3577 - val_accuracy: 0.8600 - lr: 9.9000e-04\n","Epoch 20/200\n","281/281 [==============================] - 33s 117ms/step - loss: 0.1860 - accuracy: 0.9278 - val_loss: 0.3492 - val_accuracy: 0.8560 - lr: 9.9000e-04\n","Epoch 21/200\n","281/281 [==============================] - 32s 112ms/step - loss: 0.1922 - accuracy: 0.9187 - val_loss: 0.3040 - val_accuracy: 0.8680 - lr: 9.9000e-04\n","Epoch 22/200\n","281/281 [==============================] - 30s 108ms/step - loss: 0.1802 - accuracy: 0.9270 - val_loss: 0.2993 - val_accuracy: 0.8840 - lr: 9.9000e-04\n","Epoch 23/200\n","281/281 [==============================] - 32s 114ms/step - loss: 0.1704 - accuracy: 0.9329 - val_loss: 0.3153 - val_accuracy: 0.8700 - lr: 9.9000e-04\n","Epoch 24/200\n","281/281 [==============================] - 32s 114ms/step - loss: 0.1825 - accuracy: 0.9252 - val_loss: 0.2797 - val_accuracy: 0.8880 - lr: 9.8010e-04\n","Epoch 25/200\n","281/281 [==============================] - 29s 104ms/step - loss: 0.1813 - accuracy: 0.9252 - val_loss: 0.2868 - val_accuracy: 0.8800 - lr: 9.8010e-04\n","Epoch 26/200\n","281/281 [==============================] - 33s 116ms/step - loss: 0.1656 - accuracy: 0.9305 - val_loss: 0.2658 - val_accuracy: 0.9000 - lr: 9.8010e-04\n","Epoch 27/200\n","281/281 [==============================] - 33s 116ms/step - loss: 0.1734 - accuracy: 0.9305 - val_loss: 0.3316 - val_accuracy: 0.8740 - lr: 9.8010e-04\n","Epoch 28/200\n","281/281 [==============================] - 32s 115ms/step - loss: 0.1609 - accuracy: 0.9352 - val_loss: 0.3084 - val_accuracy: 0.8920 - lr: 9.8010e-04\n","Starting training on fold num: 8\n","Epoch 1/200\n","281/281 [==============================] - 53s 131ms/step - loss: 0.4941 - accuracy: 0.7618 - val_loss: 0.3731 - val_accuracy: 0.8140 - lr: 0.0010\n","Epoch 2/200\n","281/281 [==============================] - 34s 120ms/step - loss: 0.3671 - accuracy: 0.8348 - val_loss: 0.3926 - val_accuracy: 0.8220 - lr: 0.0010\n","Epoch 3/200\n","281/281 [==============================] - 32s 114ms/step - loss: 0.3395 - accuracy: 0.8499 - val_loss: 0.3327 - val_accuracy: 0.8580 - lr: 0.0010\n","Epoch 4/200\n","281/281 [==============================] - 30s 106ms/step - loss: 0.3222 - accuracy: 0.8626 - val_loss: 0.3008 - val_accuracy: 0.8640 - lr: 0.0010\n","Epoch 5/200\n","281/281 [==============================] - 34s 120ms/step - loss: 0.2880 - accuracy: 0.8797 - val_loss: 0.2684 - val_accuracy: 0.9000 - lr: 0.0010\n","Epoch 6/200\n","281/281 [==============================] - 33s 119ms/step - loss: 0.2757 - accuracy: 0.8819 - val_loss: 0.2739 - val_accuracy: 0.8980 - lr: 0.0010\n","Epoch 7/200\n","281/281 [==============================] - 33s 117ms/step - loss: 0.2577 - accuracy: 0.8861 - val_loss: 0.2818 - val_accuracy: 0.9020 - lr: 0.0010\n","Epoch 8/200\n","281/281 [==============================] - 33s 117ms/step - loss: 0.2551 - accuracy: 0.8952 - val_loss: 0.2423 - val_accuracy: 0.9040 - lr: 0.0010\n","Epoch 9/200\n","281/281 [==============================] - 31s 109ms/step - loss: 0.2527 - accuracy: 0.8934 - val_loss: 0.2735 - val_accuracy: 0.8920 - lr: 0.0010\n","Epoch 10/200\n","281/281 [==============================] - 32s 115ms/step - loss: 0.2411 - accuracy: 0.8994 - val_loss: 0.3580 - val_accuracy: 0.8540 - lr: 0.0010\n","Epoch 11/200\n","281/281 [==============================] - 30s 107ms/step - loss: 0.2296 - accuracy: 0.9072 - val_loss: 0.2640 - val_accuracy: 0.8900 - lr: 0.0010\n","Epoch 12/200\n","281/281 [==============================] - 33s 116ms/step - loss: 0.2219 - accuracy: 0.9094 - val_loss: 0.2545 - val_accuracy: 0.9000 - lr: 0.0010\n","Epoch 13/200\n","281/281 [==============================] - 33s 116ms/step - loss: 0.2125 - accuracy: 0.9123 - val_loss: 0.3061 - val_accuracy: 0.8920 - lr: 0.0010\n","Epoch 14/200\n","281/281 [==============================] - 33s 116ms/step - loss: 0.2145 - accuracy: 0.9134 - val_loss: 0.2456 - val_accuracy: 0.8920 - lr: 9.9000e-04\n","Epoch 15/200\n","281/281 [==============================] - 32s 113ms/step - loss: 0.2145 - accuracy: 0.9147 - val_loss: 0.2931 - val_accuracy: 0.8960 - lr: 9.9000e-04\n","Epoch 16/200\n","281/281 [==============================] - 32s 115ms/step - loss: 0.2065 - accuracy: 0.9170 - val_loss: 0.3105 - val_accuracy: 0.8820 - lr: 9.9000e-04\n","Epoch 17/200\n","281/281 [==============================] - 31s 111ms/step - loss: 0.1997 - accuracy: 0.9136 - val_loss: 0.2612 - val_accuracy: 0.8920 - lr: 9.9000e-04\n","Epoch 18/200\n","281/281 [==============================] - 33s 117ms/step - loss: 0.1924 - accuracy: 0.9187 - val_loss: 0.2819 - val_accuracy: 0.8880 - lr: 9.9000e-04\n","Epoch 19/200\n","281/281 [==============================] - 30s 107ms/step - loss: 0.2006 - accuracy: 0.9154 - val_loss: 0.3468 - val_accuracy: 0.8780 - lr: 9.8010e-04\n","Epoch 20/200\n","281/281 [==============================] - 33s 119ms/step - loss: 0.1883 - accuracy: 0.9263 - val_loss: 0.2480 - val_accuracy: 0.8980 - lr: 9.8010e-04\n","Epoch 21/200\n","281/281 [==============================] - 32s 114ms/step - loss: 0.1813 - accuracy: 0.9252 - val_loss: 0.2875 - val_accuracy: 0.9000 - lr: 9.8010e-04\n","Epoch 22/200\n","281/281 [==============================] - 31s 111ms/step - loss: 0.1669 - accuracy: 0.9321 - val_loss: 0.2797 - val_accuracy: 0.8920 - lr: 9.8010e-04\n","Epoch 23/200\n","281/281 [==============================] - 33s 119ms/step - loss: 0.1770 - accuracy: 0.9252 - val_loss: 0.2449 - val_accuracy: 0.9040 - lr: 9.8010e-04\n","Starting training on fold num: 9\n","Epoch 1/200\n","281/281 [==============================] - 57s 132ms/step - loss: 0.4998 - accuracy: 0.7638 - val_loss: 0.3979 - val_accuracy: 0.8260 - lr: 0.0010\n","Epoch 2/200\n","281/281 [==============================] - 33s 117ms/step - loss: 0.3834 - accuracy: 0.8259 - val_loss: 0.3407 - val_accuracy: 0.8380 - lr: 0.0010\n","Epoch 3/200\n","281/281 [==============================] - 33s 118ms/step - loss: 0.3390 - accuracy: 0.8479 - val_loss: 0.3130 - val_accuracy: 0.8540 - lr: 0.0010\n","Epoch 4/200\n","281/281 [==============================] - 31s 109ms/step - loss: 0.3235 - accuracy: 0.8606 - val_loss: 0.3528 - val_accuracy: 0.8440 - lr: 0.0010\n","Epoch 5/200\n","281/281 [==============================] - 32s 115ms/step - loss: 0.2974 - accuracy: 0.8721 - val_loss: 0.3863 - val_accuracy: 0.8440 - lr: 0.0010\n","Epoch 6/200\n","281/281 [==============================] - 31s 108ms/step - loss: 0.2941 - accuracy: 0.8717 - val_loss: 0.3136 - val_accuracy: 0.8760 - lr: 0.0010\n","Epoch 7/200\n","281/281 [==============================] - 31s 111ms/step - loss: 0.2753 - accuracy: 0.8823 - val_loss: 0.3219 - val_accuracy: 0.8500 - lr: 0.0010\n","Epoch 8/200\n","281/281 [==============================] - 33s 117ms/step - loss: 0.2606 - accuracy: 0.8908 - val_loss: 0.2881 - val_accuracy: 0.8800 - lr: 0.0010\n","Epoch 9/200\n","281/281 [==============================] - 32s 112ms/step - loss: 0.2615 - accuracy: 0.8910 - val_loss: 0.2896 - val_accuracy: 0.8880 - lr: 0.0010\n","Epoch 10/200\n","281/281 [==============================] - 34s 120ms/step - loss: 0.2464 - accuracy: 0.8965 - val_loss: 0.3007 - val_accuracy: 0.8680 - lr: 0.0010\n","Epoch 11/200\n","281/281 [==============================] - 31s 111ms/step - loss: 0.2373 - accuracy: 0.9021 - val_loss: 0.2799 - val_accuracy: 0.8860 - lr: 0.0010\n","Epoch 12/200\n","281/281 [==============================] - 32s 113ms/step - loss: 0.2354 - accuracy: 0.9083 - val_loss: 0.2942 - val_accuracy: 0.8860 - lr: 0.0010\n","Epoch 13/200\n","281/281 [==============================] - 31s 108ms/step - loss: 0.2204 - accuracy: 0.9076 - val_loss: 0.3123 - val_accuracy: 0.8880 - lr: 0.0010\n","Epoch 14/200\n","281/281 [==============================] - 33s 119ms/step - loss: 0.2178 - accuracy: 0.9110 - val_loss: 0.3222 - val_accuracy: 0.8680 - lr: 0.0010\n","Epoch 15/200\n","281/281 [==============================] - 30s 105ms/step - loss: 0.2074 - accuracy: 0.9156 - val_loss: 0.3020 - val_accuracy: 0.8840 - lr: 9.9000e-04\n","Epoch 16/200\n","281/281 [==============================] - 34s 120ms/step - loss: 0.2097 - accuracy: 0.9107 - val_loss: 0.2798 - val_accuracy: 0.9040 - lr: 9.9000e-04\n","Epoch 17/200\n","281/281 [==============================] - 34s 119ms/step - loss: 0.2016 - accuracy: 0.9176 - val_loss: 0.3278 - val_accuracy: 0.8700 - lr: 9.9000e-04\n","Epoch 18/200\n","281/281 [==============================] - 30s 107ms/step - loss: 0.1921 - accuracy: 0.9198 - val_loss: 0.3153 - val_accuracy: 0.8900 - lr: 9.9000e-04\n","Epoch 19/200\n","281/281 [==============================] - 32s 115ms/step - loss: 0.1900 - accuracy: 0.9198 - val_loss: 0.2433 - val_accuracy: 0.9040 - lr: 9.9000e-04\n","Epoch 20/200\n","281/281 [==============================] - 34s 119ms/step - loss: 0.2017 - accuracy: 0.9159 - val_loss: 0.2681 - val_accuracy: 0.8960 - lr: 9.9000e-04\n","Epoch 21/200\n","281/281 [==============================] - 32s 114ms/step - loss: 0.1807 - accuracy: 0.9256 - val_loss: 0.2664 - val_accuracy: 0.9020 - lr: 9.9000e-04\n","Epoch 22/200\n","281/281 [==============================] - 30s 107ms/step - loss: 0.1802 - accuracy: 0.9223 - val_loss: 0.2593 - val_accuracy: 0.8980 - lr: 9.8010e-04\n","Epoch 23/200\n","281/281 [==============================] - 33s 116ms/step - loss: 0.1742 - accuracy: 0.9272 - val_loss: 0.2599 - val_accuracy: 0.8960 - lr: 9.8010e-04\n","Epoch 24/200\n","281/281 [==============================] - 33s 119ms/step - loss: 0.1698 - accuracy: 0.9296 - val_loss: 0.3335 - val_accuracy: 0.9000 - lr: 9.8010e-04\n","Epoch 25/200\n","281/281 [==============================] - 33s 117ms/step - loss: 0.1643 - accuracy: 0.9341 - val_loss: 0.3697 - val_accuracy: 0.8720 - lr: 9.8010e-04\n","Epoch 26/200\n","281/281 [==============================] - 34s 122ms/step - loss: 0.1715 - accuracy: 0.9312 - val_loss: 0.3585 - val_accuracy: 0.8920 - lr: 9.8010e-04\n","Epoch 27/200\n","281/281 [==============================] - 31s 110ms/step - loss: 0.1681 - accuracy: 0.9338 - val_loss: 0.2841 - val_accuracy: 0.9020 - lr: 9.7030e-04\n","Epoch 28/200\n","281/281 [==============================] - 34s 121ms/step - loss: 0.1644 - accuracy: 0.9358 - val_loss: 0.3221 - val_accuracy: 0.8940 - lr: 9.7030e-04\n","Epoch 29/200\n","281/281 [==============================] - 33s 116ms/step - loss: 0.1550 - accuracy: 0.9354 - val_loss: 0.3187 - val_accuracy: 0.8880 - lr: 9.7030e-04\n","Epoch 30/200\n","281/281 [==============================] - 33s 116ms/step - loss: 0.1592 - accuracy: 0.9341 - val_loss: 0.3240 - val_accuracy: 0.8880 - lr: 9.7030e-04\n","Epoch 31/200\n","281/281 [==============================] - 35s 123ms/step - loss: 0.1374 - accuracy: 0.9425 - val_loss: 0.3446 - val_accuracy: 0.8900 - lr: 9.7030e-04\n","Starting training on fold num: 10\n","Epoch 1/200\n","281/281 [==============================] - 54s 129ms/step - loss: 0.5047 - accuracy: 0.7571 - val_loss: 0.3189 - val_accuracy: 0.8680 - lr: 0.0010\n","Epoch 2/200\n","281/281 [==============================] - 32s 115ms/step - loss: 0.3777 - accuracy: 0.8324 - val_loss: 0.3537 - val_accuracy: 0.8520 - lr: 0.0010\n","Epoch 3/200\n","281/281 [==============================] - 32s 113ms/step - loss: 0.3384 - accuracy: 0.8499 - val_loss: 0.2840 - val_accuracy: 0.8720 - lr: 0.0010\n","Epoch 4/200\n","281/281 [==============================] - 31s 110ms/step - loss: 0.3082 - accuracy: 0.8617 - val_loss: 0.2832 - val_accuracy: 0.8700 - lr: 0.0010\n","Epoch 5/200\n","281/281 [==============================] - 32s 114ms/step - loss: 0.2959 - accuracy: 0.8806 - val_loss: 0.2998 - val_accuracy: 0.8680 - lr: 0.0010\n","Epoch 6/200\n","281/281 [==============================] - 31s 110ms/step - loss: 0.2878 - accuracy: 0.8812 - val_loss: 0.3178 - val_accuracy: 0.8620 - lr: 0.0010\n","Epoch 7/200\n","281/281 [==============================] - 32s 113ms/step - loss: 0.2768 - accuracy: 0.8790 - val_loss: 0.2778 - val_accuracy: 0.8700 - lr: 0.0010\n","Epoch 8/200\n","281/281 [==============================] - 31s 109ms/step - loss: 0.2563 - accuracy: 0.8870 - val_loss: 0.2655 - val_accuracy: 0.8800 - lr: 0.0010\n","Epoch 9/200\n","281/281 [==============================] - 32s 114ms/step - loss: 0.2529 - accuracy: 0.8930 - val_loss: 0.2909 - val_accuracy: 0.8740 - lr: 0.0010\n","Epoch 10/200\n","281/281 [==============================] - 32s 114ms/step - loss: 0.2423 - accuracy: 0.8965 - val_loss: 0.3118 - val_accuracy: 0.8760 - lr: 0.0010\n","Epoch 11/200\n","281/281 [==============================] - 32s 113ms/step - loss: 0.2372 - accuracy: 0.8985 - val_loss: 0.2540 - val_accuracy: 0.8860 - lr: 0.0010\n","Epoch 12/200\n","281/281 [==============================] - 32s 113ms/step - loss: 0.2304 - accuracy: 0.9041 - val_loss: 0.2487 - val_accuracy: 0.8920 - lr: 0.0010\n","Epoch 13/200\n","281/281 [==============================] - 32s 113ms/step - loss: 0.2170 - accuracy: 0.9103 - val_loss: 0.2775 - val_accuracy: 0.8740 - lr: 0.0010\n","Epoch 14/200\n","281/281 [==============================] - 30s 106ms/step - loss: 0.2175 - accuracy: 0.9094 - val_loss: 0.2965 - val_accuracy: 0.8820 - lr: 0.0010\n","Epoch 15/200\n","281/281 [==============================] - 32s 114ms/step - loss: 0.2159 - accuracy: 0.9072 - val_loss: 0.2585 - val_accuracy: 0.8800 - lr: 0.0010\n","Epoch 16/200\n","281/281 [==============================] - 31s 108ms/step - loss: 0.2144 - accuracy: 0.9092 - val_loss: 0.3053 - val_accuracy: 0.8640 - lr: 0.0010\n","Epoch 17/200\n","281/281 [==============================] - 31s 110ms/step - loss: 0.2086 - accuracy: 0.9121 - val_loss: 0.2677 - val_accuracy: 0.8860 - lr: 0.0010\n","Epoch 18/200\n","281/281 [==============================] - 31s 109ms/step - loss: 0.1912 - accuracy: 0.9167 - val_loss: 0.3005 - val_accuracy: 0.8700 - lr: 9.9000e-04\n","Epoch 19/200\n","281/281 [==============================] - 31s 108ms/step - loss: 0.1977 - accuracy: 0.9201 - val_loss: 0.2522 - val_accuracy: 0.8960 - lr: 9.9000e-04\n","Epoch 20/200\n","281/281 [==============================] - 31s 109ms/step - loss: 0.1914 - accuracy: 0.9194 - val_loss: 0.3084 - val_accuracy: 0.8760 - lr: 9.9000e-04\n","Epoch 21/200\n","281/281 [==============================] - 31s 111ms/step - loss: 0.1966 - accuracy: 0.9205 - val_loss: 0.2540 - val_accuracy: 0.8760 - lr: 9.9000e-04\n","Epoch 22/200\n","281/281 [==============================] - 31s 110ms/step - loss: 0.1866 - accuracy: 0.9261 - val_loss: 0.2841 - val_accuracy: 0.8860 - lr: 9.9000e-04\n","Epoch 23/200\n","281/281 [==============================] - 31s 111ms/step - loss: 0.1836 - accuracy: 0.9232 - val_loss: 0.2869 - val_accuracy: 0.8900 - lr: 9.9000e-04\n","Epoch 24/200\n","281/281 [==============================] - 31s 110ms/step - loss: 0.1761 - accuracy: 0.9243 - val_loss: 0.2377 - val_accuracy: 0.8940 - lr: 9.9000e-04\n","Epoch 25/200\n","281/281 [==============================] - 31s 111ms/step - loss: 0.1764 - accuracy: 0.9265 - val_loss: 0.2295 - val_accuracy: 0.8920 - lr: 9.8010e-04\n","Epoch 26/200\n","281/281 [==============================] - 31s 111ms/step - loss: 0.1704 - accuracy: 0.9298 - val_loss: 0.2798 - val_accuracy: 0.8840 - lr: 9.8010e-04\n","Epoch 27/200\n","281/281 [==============================] - 32s 115ms/step - loss: 0.1712 - accuracy: 0.9318 - val_loss: 0.2612 - val_accuracy: 0.8940 - lr: 9.8010e-04\n","Epoch 28/200\n","281/281 [==============================] - 33s 116ms/step - loss: 0.1616 - accuracy: 0.9338 - val_loss: 0.2623 - val_accuracy: 0.8820 - lr: 9.8010e-04\n","Epoch 29/200\n","281/281 [==============================] - 31s 111ms/step - loss: 0.1628 - accuracy: 0.9343 - val_loss: 0.2626 - val_accuracy: 0.8780 - lr: 9.8010e-04\n","Epoch 30/200\n","281/281 [==============================] - 31s 110ms/step - loss: 0.1545 - accuracy: 0.9365 - val_loss: 0.3042 - val_accuracy: 0.8880 - lr: 9.7030e-04\n","Epoch 31/200\n","281/281 [==============================] - 31s 109ms/step - loss: 0.1635 - accuracy: 0.9325 - val_loss: 0.2783 - val_accuracy: 0.8860 - lr: 9.7030e-04\n","Epoch 32/200\n","281/281 [==============================] - 32s 115ms/step - loss: 0.1564 - accuracy: 0.9374 - val_loss: 0.2800 - val_accuracy: 0.8880 - lr: 9.7030e-04\n","Epoch 33/200\n","281/281 [==============================] - 31s 112ms/step - loss: 0.1517 - accuracy: 0.9389 - val_loss: 0.2615 - val_accuracy: 0.8960 - lr: 9.7030e-04\n","Epoch 34/200\n","281/281 [==============================] - 32s 114ms/step - loss: 0.1444 - accuracy: 0.9416 - val_loss: 0.2686 - val_accuracy: 0.8880 - lr: 9.7030e-04\n"]}]},{"cell_type":"code","source":["# Define a list of colors for plotting\n","colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n","\n","# Create a figure for Validation visualization\n","for fold_idx in range(num_folds):\n","  plt.plot(histories[fold_idx]['val_accuracy'][:-15], color=colors[fold_idx], label=f'Fold N°{fold_idx+1}')\n","  plt.ylim(0.7, 1.0)\n","  plt.title('Accuracy')\n","  plt.legend(loc='lower left')\n","  plt.grid(alpha=.3)\n","\n","# Show the plot\n","plt.show()"],"metadata":{"id":"JkQ9wRVHmViX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate the average best epoch\n","print (best_epochs)\n","avg_epochs = int(np.mean(best_epochs))\n","print(f\"Best average epoch: {avg_epochs}\")"],"metadata":{"id":"udAqhsVTmX27","executionInfo":{"status":"ok","timestamp":1700306385759,"user_tz":-60,"elapsed":21,"user":{"displayName":"Francesco Micucci","userId":"18194798004491641315"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"919d79ea-3b19-42c6-8491-ff53a793ae25"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["[25, 39, 32, 14, 20, 15, 13, 8, 16, 19]\n","Best average epoch: 20\n"]}]},{"cell_type":"code","source":["avg_epochs = 20\n","\n","# Build the final model using the calculated average best epoch\n","final_model = build_model(feature_extractor, dropout_rate, learning_rate)\n","train_datagen = ImageDataGenerator(\n","        horizontal_flip = True,\n","        vertical_flip = True,\n","        width_shift_range = 0.1,\n","        height_shift_range = 0.1,\n","        rotation_range=10.,\n","        fill_mode='reflect')\n","\n","train_datagen.fit(images*255)\n","\n","# Train the final model on the combined training and validation data\n","final_history = final_model.fit_generator(\n","      train_datagen.flow((images)*255, labels, batch_size=16),\n","      epochs=avg_epochs,\n","      steps_per_epoch=len(images)/16,\n","      validation_data = ((images)*255, labels),\n","      callbacks = [early_stopping, lr_scheduler]\n","      ).history"],"metadata":{"id":"vNcVkgA5maAD","executionInfo":{"status":"ok","timestamp":1700307937447,"user_tz":-60,"elapsed":1150418,"user":{"displayName":"Francesco Micucci","userId":"18194798004491641315"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6a3e4287-62f3-489f-84d5-8229cff8a7b5"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","312/312 [==============================] - 115s 271ms/step - loss: 0.5051 - accuracy: 0.7592 - val_loss: 0.3720 - val_accuracy: 0.8243 - lr: 0.0010\n","Epoch 2/20\n","312/312 [==============================] - 50s 160ms/step - loss: 0.3875 - accuracy: 0.8317 - val_loss: 0.3527 - val_accuracy: 0.8445 - lr: 0.0010\n","Epoch 3/20\n","312/312 [==============================] - 46s 146ms/step - loss: 0.3243 - accuracy: 0.8565 - val_loss: 0.2735 - val_accuracy: 0.8903 - lr: 0.0010\n","Epoch 4/20\n","312/312 [==============================] - 48s 153ms/step - loss: 0.3165 - accuracy: 0.8633 - val_loss: 0.2969 - val_accuracy: 0.8747 - lr: 0.0010\n","Epoch 5/20\n","312/312 [==============================] - 54s 172ms/step - loss: 0.2909 - accuracy: 0.8735 - val_loss: 0.2868 - val_accuracy: 0.8819 - lr: 0.0010\n","Epoch 6/20\n","312/312 [==============================] - 42s 135ms/step - loss: 0.2815 - accuracy: 0.8801 - val_loss: 0.2728 - val_accuracy: 0.8769 - lr: 0.0010\n","Epoch 7/20\n","312/312 [==============================] - 50s 161ms/step - loss: 0.2606 - accuracy: 0.8915 - val_loss: 0.2351 - val_accuracy: 0.8997 - lr: 0.0010\n","Epoch 8/20\n","312/312 [==============================] - 50s 161ms/step - loss: 0.2495 - accuracy: 0.8903 - val_loss: 0.2736 - val_accuracy: 0.8883 - lr: 0.0010\n","Epoch 9/20\n","312/312 [==============================] - 51s 162ms/step - loss: 0.2492 - accuracy: 0.8949 - val_loss: 0.2358 - val_accuracy: 0.9011 - lr: 0.0010\n","Epoch 10/20\n","312/312 [==============================] - 50s 160ms/step - loss: 0.2388 - accuracy: 0.8973 - val_loss: 0.2083 - val_accuracy: 0.9129 - lr: 0.0010\n","Epoch 11/20\n","312/312 [==============================] - 50s 161ms/step - loss: 0.2421 - accuracy: 0.8955 - val_loss: 0.2084 - val_accuracy: 0.9141 - lr: 0.0010\n","Epoch 12/20\n","312/312 [==============================] - 49s 157ms/step - loss: 0.2215 - accuracy: 0.9055 - val_loss: 0.1747 - val_accuracy: 0.9303 - lr: 0.0010\n","Epoch 13/20\n","312/312 [==============================] - 48s 153ms/step - loss: 0.2286 - accuracy: 0.9071 - val_loss: 0.2042 - val_accuracy: 0.9181 - lr: 0.0010\n","Epoch 14/20\n","312/312 [==============================] - 52s 167ms/step - loss: 0.2128 - accuracy: 0.9075 - val_loss: 0.1915 - val_accuracy: 0.9189 - lr: 0.0010\n","Epoch 15/20\n","312/312 [==============================] - 51s 162ms/step - loss: 0.2087 - accuracy: 0.9167 - val_loss: 0.2058 - val_accuracy: 0.9145 - lr: 0.0010\n","Epoch 16/20\n","312/312 [==============================] - 50s 160ms/step - loss: 0.2092 - accuracy: 0.9165 - val_loss: 0.2262 - val_accuracy: 0.9049 - lr: 0.0010\n","Epoch 17/20\n","312/312 [==============================] - 50s 160ms/step - loss: 0.2096 - accuracy: 0.9111 - val_loss: 0.1783 - val_accuracy: 0.9243 - lr: 0.0010\n","Epoch 18/20\n","312/312 [==============================] - 44s 141ms/step - loss: 0.2011 - accuracy: 0.9169 - val_loss: 0.2007 - val_accuracy: 0.9165 - lr: 9.9000e-04\n","Epoch 19/20\n","312/312 [==============================] - 52s 168ms/step - loss: 0.1901 - accuracy: 0.9219 - val_loss: 0.1526 - val_accuracy: 0.9365 - lr: 9.9000e-04\n","Epoch 20/20\n","312/312 [==============================] - 50s 161ms/step - loss: 0.1880 - accuracy: 0.9275 - val_loss: 0.1761 - val_accuracy: 0.9291 - lr: 9.9000e-04\n"]}]},{"cell_type":"code","source":["# Save the model\n","final_model.save('2ndSubmission_TL')\n","with open('2ndSubmission_TL/history.pkl', 'wb') as f:\n","  pickle.dump(final_history, f)"],"metadata":{"id":"hiTjCUmamb2p","executionInfo":{"status":"ok","timestamp":1700307971877,"user_tz":-60,"elapsed":34448,"user":{"displayName":"Francesco Micucci","userId":"18194798004491641315"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["### Fine Tuning"],"metadata":{"id":"wtCJsp8LtDNv"}},{"cell_type":"code","source":["# Define the number of folds for cross-validation\n","num_folds = 10\n","\n","# Initialize lists to store training histories, scores, and best epochs\n","histories = []\n","scores = []\n","best_epochs = []\n","\n","# Create a KFold cross-validation object\n","kfold = KFold(n_splits=num_folds, shuffle=True)\n","\n","# Loop through each fold\n","for fold_idx, (train_idx, valid_idx) in enumerate(kfold.split(images, labels)):\n","\n","  print(\"Starting training on fold num: {}\".format(fold_idx+1))\n","\n","  # Init model\n","  k_model = tfk.models.load_model('2ndSubmission_TL')\n","  train_datagen = ImageDataGenerator(\n","          horizontal_flip = True,\n","          vertical_flip = True,\n","          width_shift_range = 0.1,\n","          height_shift_range = 0.1,\n","          rotation_range=10.,\n","          fill_mode='reflect')\n","\n","  train_datagen.fit((images)[train_idx]*255)\n","\n","  # Set all ConvNeXtLarge layers as trainable\n","  k_model.get_layer('convnext_large').trainable = True\n","  for i, layer in enumerate(k_model.get_layer('convnext_large').layers):\n","    print(i, layer.name, layer.trainable)\n","\n","  # Freeze first N layers, e.g., until the 133rd one\n","  N = 286\n","  for i, layer in enumerate(k_model.get_layer('convnext_large').layers[:N]):\n","    layer.trainable=False\n","  for i, layer in enumerate(k_model.get_layer('convnext_large').layers):\n","    print(i, layer.name, layer.trainable)\n","  k_model.summary()\n","\n","  # Compile the model\n","  k_model.compile(loss=tfk.losses.CategoricalCrossentropy(),\n","                  optimizer=tfk.optimizers.Adam(learning_rate),\n","                  metrics='accuracy')\n","\n","  # Train the model on the training data for this fold\n","  history = k_model.fit_generator(\n","      train_datagen.flow((images)[train_idx]*255, labels[train_idx], batch_size=16),\n","      epochs=200,\n","      steps_per_epoch=len((images)[train_idx])/16,\n","      validation_data = ((images)[valid_idx]*255, labels[valid_idx]),\n","      callbacks = [early_stopping, lr_scheduler]\n","      ).history\n","\n","  # Evaluate the model on the validation data for this fold\n","  score = k_model.evaluate((images)[valid_idx]*255, labels[valid_idx], verbose=0)\n","  scores.append(score[1])\n","\n","  # Calculate the best epoch for early stopping\n","  best_epoch = len(history['loss']) - 15\n","  best_epochs.append(best_epoch)\n","\n","  # Store the training history for this fold\n","  histories.append(history)"],"metadata":{"id":"qu6iVCdntOlF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define a list of colors for plotting\n","colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n","\n","# Create a figure for Validation visualization\n","for fold_idx in range(num_folds):\n","  plt.plot(histories[fold_idx]['val_accuracy'][:-15], color=colors[fold_idx], label=f'Fold N°{fold_idx+1}')\n","  plt.ylim(0.7, 1.0)\n","  plt.title('Accuracy')\n","  plt.legend(loc='lower left')\n","  plt.grid(alpha=.3)\n","\n","# Show the plot\n","plt.show()"],"metadata":{"id":"BBVC6DcouGJA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate the average best epoch\n","print (best_epochs)\n","avg_epochs = int(np.mean(best_epochs))\n","print(f\"Best average epoch: {avg_epochs}\")"],"metadata":{"id":"a_Tv1sZyuJKY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Build the final model using the calculated average best epoch\n","final_model = tfk.models.load_model('2ndSubmission_TL')\n","train_datagen = ImageDataGenerator(\n","        horizontal_flip = True,\n","        vertical_flip = True,\n","        width_shift_range = 0.1,\n","        height_shift_range = 0.1,\n","        rotation_range=10.,\n","        fill_mode='reflect')\n","\n","train_datagen.fit((images)*255)\n","\n","# Set all ConvNeXtLarge layers as trainable\n","final_model.get_layer('convnext_large').trainable = True\n","for i, layer in enumerate(final_model.get_layer('convnext_large').layers):\n","  print(i, layer.name, layer.trainable)\n","\n","# Freeze first N layers, e.g., until the 133rd one\n","N = 286\n","for i, layer in enumerate(final_model.get_layer('convnext_large').layers[:N]):\n","  layer.trainable=False\n","for i, layer in enumerate(final_model.get_layer('convnext_large').layers):\n","  print(i, layer.name, layer.trainable)\n","final_model.summary()\n","\n","# Compile the model\n","final_model.compile(loss=tfk.losses.CategoricalCrossentropy(),\n","                optimizer=tfk.optimizers.Adam(learning_rate),\n","                metrics='accuracy')\n","\n","# Train the final model on the combined training and validation data\n","final_history = final_model.fit_generator(\n","      train_datagen.flow((images)*255, labels, batch_size=16),\n","      epochs=avg_epochs,\n","      steps_per_epoch=len(images)/16,\n","      validation_data = ((images)*255, labels),\n","      callbacks = [early_stopping, lr_scheduler]\n","      ).history"],"metadata":{"id":"kXm49_deuMkw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save the model\n","final_model.save('2ndSubmission_FT')\n","with open('2ndSubmission_FT/history.pkl', 'wb') as f:\n","  pickle.dump(final_history, f)"],"metadata":{"id":"M_9aJr2AuPL9"},"execution_count":null,"outputs":[]}]}